# import requests
# import json
# import time
# from selenium import webdriver
# from selenium.webdriver.chrome.service import Service
# from selenium.webdriver.common.by import By
# from selenium.webdriver.support.ui import WebDriverWait
# from selenium.webdriver.support import expected_conditions as EC
# from webdriver_manager.chrome import ChromeDriverManager

# def get_service_list_for_test(count=10):
#     """
#     cURL ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì™„ì „íˆ ìˆ˜ì •ëœ API ìš”ì²­ í•¨ìˆ˜ì…ë‹ˆë‹¤.
#     """
#     print(f"âœ… í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ {count}ê°œì˜ ì„œë¹„ìŠ¤ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.")
    
#     # 1. URL ë³€ê²½
#     list_url = "https://www.bokjiro.go.kr/ssis-tbu/TWAT52005M/twataa/wlfareInfo/selectWlfareInfo.do"
    
#     # 2. í—¤ë” ë³€ê²½ (cURL ê¸°ë°˜)
#     headers = {
#         'Accept': 'application/json, text/javascript, */*; q=0.01',
#         'Content-Type': 'application/json; charset=UTF-8',
#         'Origin': 'https://www.bokjiro.go.kr',
#         'Referer': 'https://www.bokjiro.go.kr/ssis-tbu/twataa/wlfareInfo/moveTWAT52005M.do',
#         'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36',
#         'X-Requested-With': 'XMLHttpRequest'
#     }
    
#     # 3. ë°ì´í„° í˜•ì‹ ë³€ê²½ (cURL ê¸°ë°˜ JSON)
#     payload = {
#         "dmSearchParam": {
#             "page": "1", # í˜ì´ì§€ ë²ˆí˜¸ëŠ” ì—¬ê¸°ì—ì„œ ë³€ê²½ë©ë‹ˆë‹¤.
#             "pageUnit": str(count), # í•œ í˜ì´ì§€ì— ê°€ì ¸ì˜¬ ê°œìˆ˜
#             "onlineYn": "", "searchTerm": "", "tabId": "1", "orderBy": "date",
#             "bkjrLftmCycCd": "", "daesang": "", "period": "", "age": "",
#             "region": "", "jjim": "", "subject": "", "favoriteKeyword": "Y",
#             "sido": "", "gungu": "", "endYn": "N"
#         },
#         "dmScr": {
#             "curScrId": "tbu/app/twat/twata/twataa/TWAT52005M",
#             "befScrId": ""
#         }
#     }
    
#     try:
#         # requests.post í˜¸ì¶œ ì‹œ 'data=' ëŒ€ì‹  'json='ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
#         response = requests.post(list_url, headers=headers, json=payload)
#         response.raise_for_status()
#         data = response.json()
        
#         # 4. ì‘ë‹µ ë°ì´í„° êµ¬ì¡°ì— ë§ì¶° íŒŒì‹± ë¡œì§ ë³€ê²½
#         services = data.get("data", {}).get("resultList", [])
        
#         service_list = [
#             {"id": s.get("wlfareInfoId"), "name": s.get("wlfareInfoNm")}
#             for s in services
#         ]
#         print(f"âœ”ï¸ {len(service_list)}ê°œ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì„±ê³µ.")
#         return service_list
        
#     except Exception as e:
#         print(f"âŒ ëª©ë¡ ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
#         return []

# def scrape_details_for_test(services):
#     """
#     Seleniumìœ¼ë¡œ ê° ì„œë¹„ìŠ¤ì˜ 'ì§€ì›ëŒ€ìƒ' ê´€ë ¨ ë‚´ìš©ì„ ìŠ¤í¬ë˜í•‘í•©ë‹ˆë‹¤. (ì´ ë¶€ë¶„ì€ ë³€ê²½ ì—†ìŒ)
#     """
#     print("\nâœ… Seleniumìœ¼ë¡œ ìƒì„¸ ì •ë³´ ìŠ¤í¬ë˜í•‘ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    
#     options = webdriver.ChromeOptions()
#     options.add_argument("--headless")
#     options.add_argument("--no-sandbox")
#     options.add_argument("--disable-dev-shm-usage")
#     options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36")

#     driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
    
#     results = []
#     total = len(services)
    
#     for i, service in enumerate(services):
#         service_id = service['id']
#         service_name = service['name']
        
#         if not service_id: continue
            
#         detail_url = f"https://www.bokjiro.go.kr/ssis-tbu/twataa/wlfareInfo/moveTWAT52011M.do?wlfareInfoId={service_id}&wlfareInfoReldBztpCd=01"
        
#         print(f"({i+1}/{total}) ìŠ¤í¬ë˜í•‘ ì¤‘: {service_name[:30]}...")
        
#         try:
#             driver.get(detail_url)
#             wait = WebDriverWait(driver, 10)
#             target_content_area = wait.until(
#                 EC.presence_of_element_located((By.XPATH, "//h3[text()='ì§€ì›ëŒ€ìƒ']/following-sibling::div[1]"))
#             )
#             content_text = target_content_area.text.strip()
            
#             results.append({
#                 "ì„œë¹„ìŠ¤ëª…": service_name,
#                 "ì§€ì›ëŒ€ìƒ_ë‚´ìš©": content_text
#             })
            
#         except Exception as e:
#             print(f"  - ì˜¤ë¥˜ ë°œìƒ: {service_name} ({e})")
#             results.append({
#                 "ì„œë¹„ìŠ¤ëª…": service_name,
#                 "ì§€ì›ëŒ€ìƒ_ë‚´ìš©": "ìŠ¤í¬ë˜í•‘ ì˜¤ë¥˜ ë°œìƒ"
#             })
    
#     driver.quit()
#     return results

# # --- ë©”ì¸ ì‹¤í–‰ ---
# if __name__ == "__main__":
#     # 10ê°œ ëŒ€ì‹  5ê°œë§Œ ê°€ì ¸ì˜¤ë„ë¡ ìˆ˜ì • (í…ŒìŠ¤íŠ¸ ì†ë„ í–¥ìƒ)
#     test_services = get_service_list_for_test(5)
    
#     if test_services:
#         scraped_data = scrape_details_for_test(test_services)
        
#         print("\n\n--- ìµœì¢… ìŠ¤í¬ë˜í•‘ ê²°ê³¼ (5ê°œ) ---")
#         for item in scraped_data:
#             print(f"\n[ì„œë¹„ìŠ¤ëª…] {item['ì„œë¹„ìŠ¤ëª…']}")
#             print(f"[ì§€ì›ëŒ€ìƒ ë‚´ìš©]\n{item['ì§€ì›ëŒ€ìƒ_ë‚´ìš©']}")
#             print("-" * 20)

# 
# import requests
# import json
# import time
# from selenium import webdriver
# from selenium.webdriver.chrome.service import Service
# from selenium.webdriver.common.by import By
# from selenium.webdriver.support.ui import WebDriverWait
# from selenium.webdriver.support import expected_conditions as EC
# from webdriver_manager.chrome import ChromeDriverManager

# def get_service_list_for_test(count=10):
#     """
#     ì„œë²„ ì‘ë‹µ êµ¬ì¡°ì— ë§ì¶° íŒŒì‹± ë¡œì§ì„ ìˆ˜ì •í•œ ìµœì¢… ë²„ì „ì…ë‹ˆë‹¤.
#     """
#     print(f"âœ… {count}ê°œì˜ ì„œë¹„ìŠ¤ ëª©ë¡ì„ ìš”ì²­í•©ë‹ˆë‹¤.")
    
#     list_url = "https://www.bokjiro.go.kr/ssis-tbu/TWAT52005M/twataa/wlfareInfo/selectWlfareInfo.do"
    
#     headers = {
#         'Accept': 'application/json, text/javascript, */*; q=0.01',
#         'Content-Type': 'application/json; charset=UTF-8',
#         'Origin': 'https://www.bokjiro.go.kr',
#         'Referer': 'https://www.bokjiro.go.kr/ssis-tbu/twataa/wlfareInfo/moveTWAT52005M.do',
#         'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36',
#         'X-Requested-With': 'XMLHttpRequest'
#     }
    
#     payload = {
#         "dmSearchParam": {
#             "page": "1", "pageUnit": str(count), "onlineYn": "", "searchTerm": "", "tabId": "1", "orderBy": "date",
#             "bkjrLftmCycCd": "", "daesang": "", "period": "", "age": "", "region": "", "jjim": "",
#             "subject": "", "favoriteKeyword": "Y", "sido": "", "gungu": "", "endYn": "N"
#         },
#         "dmScr": {"curScrId": "tbu/app/twat/twata/twataa/TWAT52005M", "befScrId": ""}
#     }
    
#     try:
#         response = requests.post(list_url, headers=headers, json=payload)
#         response.raise_for_status()
#         data = response.json()
        
#         # --- âœ¨ ìˆ˜ì •í•œ ë¶€ë¶„ ì‹œì‘ âœ¨ ---
#         # dsServiceList0, 1, 2, 3 ì— ë‚˜ë‰˜ì–´ ë‹´ê¸´ ëª©ë¡ì„ ëª¨ë‘ ê°€ì ¸ì™€ í•©ì¹©ë‹ˆë‹¤.
#         all_services_raw = []
#         for i in range(4): # dsServiceList0 ë¶€í„° dsServiceList3 ê¹Œì§€ í™•ì¸
#             all_services_raw.extend(data.get(f"dsServiceList{i}", []))
        
#         # í•„ìš”í•œ IDì™€ ì´ë¦„ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.
#         service_list = [
#             {"id": s.get("WLFARE_INFO_ID"), "name": s.get("WLFARE_INFO_NM")}
#             for s in all_services_raw
#         ]
#         # --- âœ¨ ìˆ˜ì •í•œ ë¶€ë¶„ ë âœ¨ ---
        
#         # ì‹¤ì œ ê°€ì ¸ì˜¨ ì„œë¹„ìŠ¤ ê°œìˆ˜ë§Œí¼ë§Œ ìŠ¬ë¼ì´ì‹± (ìš”ì²­ ê°œìˆ˜ë³´ë‹¤ ë§ì„ ìˆ˜ ìˆìŒ)
#         service_list = service_list[:count]

#         print(f"âœ”ï¸ {len(service_list)}ê°œ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì„±ê³µ.")
#         return service_list
        
#     except Exception as e:
#         print(f"âŒ ëª©ë¡ ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
#         return []

# def scrape_details_for_test(services):
#     """
#     Seleniumìœ¼ë¡œ ê° ì„œë¹„ìŠ¤ì˜ 'ì§€ì›ëŒ€ìƒ' ê´€ë ¨ ë‚´ìš©ì„ ìŠ¤í¬ë˜í•‘í•©ë‹ˆë‹¤.
#     """
#     print("\nâœ… Seleniumìœ¼ë¡œ ìƒì„¸ ì •ë³´ ìŠ¤í¬ë˜í•‘ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    
#     options = webdriver.ChromeOptions()
#     options.add_argument("--headless")
#     options.add_argument("--no-sandbox")
#     options.add_argument("--disable-dev-shm-usage")
#     options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36")

#     driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
    
#     results = []
#     total = len(services)
    
#     for i, service in enumerate(services):
#         service_id = service['id']
#         service_name = service['name']
        
#         if not service_id: continue
            
#         detail_url = f"https://www.bokjiro.go.kr/ssis-tbu/twataa/wlfareInfo/moveTWAT52011M.do?wlfareInfoId={service_id}&wlfareInfoReldBztpCd=01"
        
#         print(f"({i+1}/{total}) ìŠ¤í¬ë˜í•‘ ì¤‘: {service_name[:30]}...")
        
#         try:
#             driver.get(detail_url)
#             wait = WebDriverWait(driver, 10)
#             target_content_area = wait.until(
#                 EC.presence_of_element_located((By.XPATH, "//h3[text()='ì§€ì›ëŒ€ìƒ']/following-sibling::div[1]"))
#             )
#             content_text = target_content_area.text.strip()
            
#             results.append({
#                 "ì„œë¹„ìŠ¤ëª…": service_name,
#                 "ì§€ì›ëŒ€ìƒ_ë‚´ìš©": content_text
#             })
            
#         except Exception as e:
#             print(f"  - ì˜¤ë¥˜ ë°œìƒ: {service_name} ({e})")
#             results.append({
#                 "ì„œë¹„ìŠ¤ëª…": service_name,
#                 "ì§€ì›ëŒ€ìƒ_ë‚´ìš©": "ìŠ¤í¬ë˜í•‘ ì˜¤ë¥˜ ë°œìƒ"
#             })
    
#     driver.quit()
#     return results

# # --- ë©”ì¸ ì‹¤í–‰ ---
# if __name__ == "__main__":
#     test_services = get_service_list_for_test(10)
    
#     if test_services:
#         scraped_data = scrape_details_for_test(test_services)
        
#         print("\n\n--- ìµœì¢… ìŠ¤í¬ë˜í•‘ ê²°ê³¼ (10ê°œ) ---")
#         for item in scraped_data:
#             print(f"\n[ì„œë¹„ìŠ¤ëª…] {item['ì„œë¹„ìŠ¤ëª…']}")
#             print(f"[ì§€ì›ëŒ€ìƒ ë‚´ìš©]\n{item['ì§€ì›ëŒ€ìƒ_ë‚´ìš©']}")
#             print("-" * 20)

# import requests
# import json
# import time
# from selenium import webdriver
# from selenium.webdriver.chrome.service import Service
# from selenium.webdriver.common.by import By
# from selenium.webdriver.support.ui import WebDriverWait
# from selenium.webdriver.support import expected_conditions as EC
# from webdriver_manager.chrome import ChromeDriverManager

# def get_service_list_for_test(count=10):
#     # ì´ ë¶€ë¶„ì€ ì •ìƒ ì‘ë™í•˜ë¯€ë¡œ ë³€ê²½ ì—†ìŠµë‹ˆë‹¤.
#     print(f"âœ… {count}ê°œì˜ ì„œë¹„ìŠ¤ ëª©ë¡ì„ ìš”ì²­í•©ë‹ˆë‹¤.")
#     list_url = "https://www.bokjiro.go.kr/ssis-tbu/TWAT52005M/twataa/wlfareInfo/selectWlfareInfo.do"
#     headers = {
#         'Accept': 'application/json, text/javascript, */*; q=0.01',
#         'Content-Type': 'application/json; charset=UTF-8',
#         'Origin': 'https://www.bokjiro.go.kr',
#         'Referer': 'https://www.bokjiro.go.kr/ssis-tbu/twataa/wlfareInfo/moveTWAT52005M.do',
#         'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36',
#         'X-Requested-With': 'XMLHttpRequest'
#     }
#     payload = {
#         "dmSearchParam": {"page": "1", "pageUnit": str(count), "onlineYn": "", "searchTerm": "", "tabId": "1", "orderBy": "date", "bkjrLftmCycCd": "", "daesang": "", "period": "", "age": "", "region": "", "jjim": "", "subject": "", "favoriteKeyword": "Y", "sido": "", "gungu": "", "endYn": "N"},
#         "dmScr": {"curScrId": "tbu/app/twat/twata/twataa/TWAT52005M", "befScrId": ""}
#     }
#     try:
#         response = requests.post(list_url, headers=headers, json=payload)
#         response.raise_for_status()
#         data = response.json()
#         all_services_raw = []
#         for i in range(4):
#             all_services_raw.extend(data.get(f"dsServiceList{i}", []))
#         service_list = [{"id": s.get("WLFARE_INFO_ID"), "name": s.get("WLFARE_INFO_NM")} for s in all_services_raw]
#         service_list = service_list[:count]
#         print(f"âœ”ï¸ {len(service_list)}ê°œ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì„±ê³µ.")
#         return service_list
#     except Exception as e:
#         print(f"âŒ ëª©ë¡ ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
#         return []

# def scrape_details_for_test(services):
#     """
#     ì•ˆì •ì„± ì˜µì…˜ì„ ì¶”ê°€í•˜ê³  headless ëª¨ë“œë¥¼ ë¹„í™œì„±í™”í•˜ì—¬ ìˆ˜ì •í•œ ë²„ì „ì…ë‹ˆë‹¤.
#     """
#     print("\nâœ… Seleniumìœ¼ë¡œ ìƒì„¸ ì •ë³´ ìŠ¤í¬ë˜í•‘ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    
#     options = webdriver.ChromeOptions()
    
#     # --- âœ¨ ìˆ˜ì •ëœ ë¶€ë¶„ ì‹œì‘ âœ¨ ---
#     # options.add_argument("--headless")  # ì›ì¸ì´ ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì ì‹œ ì£¼ì„ ì²˜ë¦¬ (ì°½ì´ ë³´ì´ê²Œ ë¨)
#     options.add_argument("--no-sandbox")
#     options.add_argument("--disable-dev-shm-usage")
    
#     # ì•ˆì •ì„±ì„ ë†’ì´ëŠ” ì˜µì…˜ ì¶”ê°€
#     options.add_argument("--disable-gpu") # GPU ê°€ì† ë¹„í™œì„±í™” (ì¶©ëŒ ë°©ì§€)
#     options.add_argument("window-size=1920x1080") # ì°½ í¬ê¸° ì§€ì •
#     options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36")
#     # --- âœ¨ ìˆ˜ì •ëœ ë¶€ë¶„ ë âœ¨ ---

#     driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
    
#     results = []
#     total = len(services)
    
#     for i, service in enumerate(services):
#         service_id = service['id']
#         service_name = service['name']
        
#         if not service_id: continue
            
#         detail_url = f"https://www.bokjiro.go.kr/ssis-tbu/twataa/wlfareInfo/moveTWAT52011M.do?wlfareInfoId={service_id}&wlfareInfoReldBztpCd=01"
        
#         print(f"({i+1}/{total}) ìŠ¤í¬ë˜í•‘ ì¤‘: {service_name[:30]}...")
        
#         try:
#             driver.get(detail_url)
#             wait = WebDriverWait(driver, 10)
#             target_content_area = wait.until(
#                 EC.presence_of_element_located((By.XPATH, "//h3[text()='ì§€ì›ëŒ€ìƒ']/following-sibling::div[1]"))
#             )
#             content_text = target_content_area.text.strip()
            
#             results.append({"ì„œë¹„ìŠ¤ëª…": service_name, "ì§€ì›ëŒ€ìƒ_ë‚´ìš©": content_text})
            
#         except Exception as e:
#             # ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ë” ìì„¸íˆ ë³´ê¸° ìœ„í•´ eë¥¼ ì¶œë ¥í•˜ë„ë¡ ë³€ê²½
#             print(f"  - ì˜¤ë¥˜ ë°œìƒ: {service_name} ({e.__class__.__name__})")
#             results.append({"ì„œë¹„ìŠ¤ëª…": service_name, "ì§€ì›ëŒ€ìƒ_ë‚´ìš©": "ìŠ¤í¬ë˜í•‘ ì˜¤ë¥˜ ë°œìƒ"})
    
#     driver.quit()
#     return results

# # --- ë©”ì¸ ì‹¤í–‰ ---
# if __name__ == "__main__":
#     test_services = get_service_list_for_test(10)
    
#     if test_services:
#         scraped_data = scrape_details_for_test(test_services)
        
#         print("\n\n--- ìµœì¢… ìŠ¤í¬ë˜í•‘ ê²°ê³¼ (10ê°œ) ---")
#         for item in scraped_data:
#             print(f"\n[ì„œë¹„ìŠ¤ëª…] {item['ì„œë¹„ìŠ¤ëª…']}")
#             print(f"[ì§€ì›ëŒ€ìƒ ë‚´ìš©]\n{item['ì§€ì›ëŒ€ìƒ_ë‚´ìš©']}")
#             print("-" * 20)

# import requests
# import json
# import time
# from selenium import webdriver
# from selenium.webdriver.chrome.service import Service
# from selenium.webdriver.common.by import By
# from selenium.webdriver.support.ui import WebDriverWait
# from selenium.webdriver.support import expected_conditions as EC
# from selenium.common.exceptions import TimeoutException # ì˜ˆì™¸ ì²˜ë¦¬ë¥¼ ìœ„í•´ ì¶”ê°€
# from webdriver_manager.chrome import ChromeDriverManager

# # get_service_list_for_test í•¨ìˆ˜ëŠ” ë³€ê²½ ì—†ì´ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
# def get_service_list_for_test(count=10):
#     print(f"âœ… {count}ê°œì˜ ì„œë¹„ìŠ¤ ëª©ë¡ì„ ìš”ì²­í•©ë‹ˆë‹¤.")
#     list_url = "https://www.bokjiro.go.kr/ssis-tbu/TWAT52005M/twataa/wlfareInfo/selectWlfareInfo.do"
#     headers = {'Accept': 'application/json, text/javascript, */*; q=0.01', 'Content-Type': 'application/json; charset=UTF-8', 'Origin': 'https://www.bokjiro.go.kr', 'Referer': 'https://www.bokjiro.go.kr/ssis-tbu/twataa/wlfareInfo/moveTWAT52005M.do', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36', 'X-Requested-With': 'XMLHttpRequest'}
#     payload = {"dmSearchParam": {"page": "1", "pageUnit": str(count), "onlineYn": "", "searchTerm": "", "tabId": "1", "orderBy": "date", "bkjrLftmCycCd": "", "daesang": "", "period": "", "age": "", "region": "", "jjim": "", "subject": "", "favoriteKeyword": "Y", "sido": "", "gungu": "", "endYn": "N"}, "dmScr": {"curScrId": "tbu/app/twat/twata/twataa/TWAT52005M", "befScrId": ""}}
#     try:
#         response = requests.post(list_url, headers=headers, json=payload)
#         response.raise_for_status()
#         data = response.json()
#         all_services_raw = []
#         for i in range(4):
#             all_services_raw.extend(data.get(f"dsServiceList{i}", []))
#         service_list = [{"id": s.get("WLFARE_INFO_ID"), "name": s.get("WLFARE_INFO_NM")} for s in all_services_raw]
#         service_list = service_list[:count]
#         print(f"âœ”ï¸ {len(service_list)}ê°œ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì„±ê³µ.")
#         return service_list
#     except Exception as e:
#         print(f"âŒ ëª©ë¡ ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
#         return []

# def scrape_details_for_test(services):
#     """
#     íŒì—…ì°½ ë‹«ê¸° ë¡œì§ì´ ì¶”ê°€ëœ ìµœì¢… ë²„ì „ì…ë‹ˆë‹¤.
#     """
#     print("\nâœ… Seleniumìœ¼ë¡œ ìƒì„¸ ì •ë³´ ìŠ¤í¬ë˜í•‘ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    
#     options = webdriver.ChromeOptions()
#     # options.add_argument("--headless") # ìµœì¢… ì™„ë£Œ ì‹œ ì£¼ì„ í•´ì œí•˜ì—¬ ì‚¬ìš©
#     options.add_argument("--no-sandbox")
#     options.add_argument("--disable-dev-shm-usage")
#     options.add_argument("--disable-gpu")
#     options.add_argument("window-size=1920x1080")
#     options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36")

#     driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
    
#     results = []
#     total = len(services)
    
#     for i, service in enumerate(services):
#         service_id = service['id']
#         service_name = service['name']
        
#         if not service_id: continue
            
#         detail_url = f"https://www.bokjiro.go.kr/ssis-tbu/twataa/wlfareInfo/moveTWAT52011M.do?wlfareInfoId={service_id}&wlfareInfoReldBztpCd=01"
        
#         print(f"({i+1}/{total}) ìŠ¤í¬ë˜í•‘ ì¤‘: {service_name[:30]}...")
        
#         try:
#             driver.get(detail_url)
#             wait = WebDriverWait(driver, 10)
            
#             # --- âœ¨ íŒì—… ì²˜ë¦¬ ë¡œì§ ì‹œì‘ âœ¨ ---
#             try:
#                 # íŒì—…ì˜ 'ë‹«ê¸°' ë²„íŠ¼ì´ 5ì´ˆ ì•ˆì— ë‚˜íƒ€ë‚˜ë©´ ì°¾ì•„ì„œ í´ë¦­
#                 popup_close_button = WebDriverWait(driver, 5).until(
#                     EC.element_to_be_clickable((By.CSS_SELECTOR, "#research_pop .btn-close-pop"))
#                 )
#                 popup_close_button.click()
#                 print("  - íŒì—…ì°½ì„ ë‹«ì•˜ìŠµë‹ˆë‹¤.")
#             except TimeoutException:
#                 # 5ì´ˆ ì•ˆì— íŒì—…ì´ ì•ˆ ë‚˜íƒ€ë‚˜ë©´ ê·¸ëƒ¥ ë„˜ì–´ê°
#                 print("  - íŒì—…ì´ ë‚˜íƒ€ë‚˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
#                 pass
#             # --- âœ¨ íŒì—… ì²˜ë¦¬ ë¡œì§ ë âœ¨ ---
            
#             # ì´ì œ íŒì—…ì´ ì—†ìœ¼ë¯€ë¡œ, ì›ë˜ ì°¾ìœ¼ë ¤ë˜ 'ì§€ì›ëŒ€ìƒ' ë‚´ìš©ì„ ì°¾ìŠµë‹ˆë‹¤.
#             target_content_area = wait.until(
#                 EC.presence_of_element_located((By.XPATH, "//h3[contains(text(),'ì§€ì›ëŒ€ìƒ')]/following-sibling::div[1]"))
#             )
#             content_text = target_content_area.text.strip()
            
#             results.append({"ì„œë¹„ìŠ¤ëª…": service_name, "ì§€ì›ëŒ€ìƒ_ë‚´ìš©": content_text})
            
#         except Exception as e:
#             print(f"  - ì˜¤ë¥˜ ë°œìƒ: {service_name} ({e.__class__.__name__})")
#             results.append({"ì„œë¹„ìŠ¤ëª…": service_name, "ì§€ì›ëŒ€ìƒ_ë‚´ìš©": "ìŠ¤í¬ë˜í•‘ ì˜¤ë¥˜ ë°œìƒ"})
    
#     driver.quit()
#     return results

# # --- ë©”ì¸ ì‹¤í–‰ ---
# if __name__ == "__main__":
#     test_services = get_service_list_for_test(10)
    
#     if test_services:
#         scraped_data = scrape_details_for_test(test_services)
        
#         print("\n\n--- ìµœì¢… ìŠ¤í¬ë˜í•‘ ê²°ê³¼ (10ê°œ) ---")
#         for item in scraped_data:
#             print(f"\n[ì„œë¹„ìŠ¤ëª…] {item['ì„œë¹„ìŠ¤ëª…']}")
#             print(f"[ì§€ì›ëŒ€ìƒ ë‚´ìš©]\n{item['ì§€ì›ëŒ€ìƒ_ë‚´ìš©']}")
#             print("-" * 20)

# import requests
# import json
# import csv
# import time
# from selenium import webdriver
# from selenium.webdriver.chrome.service import Service
# from selenium.webdriver.common.by import By
# from selenium.webdriver.support.ui import WebDriverWait
# from selenium.webdriver.support import expected_conditions as EC
# from selenium.common.exceptions import TimeoutException
# from webdriver_manager.chrome import ChromeDriverManager

# def get_all_service_list():
#     """
#     ë³µì§€ë¡œ APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì „ì²´ ì„œë¹„ìŠ¤ ëª©ë¡(ID, ì´ë¦„)ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
#     í˜ì´ì§€ë¥¼ ìë™ìœ¼ë¡œ ë„˜ê¸°ë©° ëª¨ë“  ëª©ë¡ì„ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
#     """
#     print("âœ… [1ë‹¨ê³„] ì „ì²´ ë³µì§€ ì„œë¹„ìŠ¤ ëª©ë¡ ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
#     list_url = "https://www.bokjiro.go.kr/ssis-tbu/TWAT52005M/twataa/wlfareInfo/selectWlfareInfo.do"
#     headers = {
#         'Accept': 'application/json, text/javascript, */*; q=0.01',
#         'Content-Type': 'application/json; charset=UTF-8',
#         'Referer': 'https://www.bokjiro.go.kr/ssis-tbu/twataa/wlfareInfo/moveTWAT52005M.do',
#         'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36',
#     }
#     payload_template = {
#         "dmSearchParam": {"page": "1", "pageUnit": "100", "orderBy": "date", "endYn": "N"},
#         "dmScr": {"curScrId": "tbu/app/twat/twata/twataa/TWAT52005M"}
#     }
    
#     all_services = []
#     current_page = 1
    
#     while True:
#         print(f"ğŸ“„ ëª©ë¡ {current_page}í˜ì´ì§€ë¥¼ ìš”ì²­í•©ë‹ˆë‹¤...")
#         payload_template["dmSearchParam"]["page"] = str(current_page)
        
#         try:
#             response = requests.post(list_url, headers=headers, json=payload_template)
#             response.raise_for_status()
#             data = response.json()
            
#             services_on_page = []
#             for i in range(4): # dsServiceList0 ~ dsServiceList3 í™•ì¸
#                 services_on_page.extend(data.get(f"dsServiceList{i}", []))

#             if not services_on_page:
#                 print("âœ”ï¸ ë” ì´ìƒ ê°€ì ¸ì˜¬ ëª©ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
#                 break
            
#             for service in services_on_page:
#                 all_services.append({
#                     "id": service.get("WLFARE_INFO_ID"),
#                     "name": service.get("WLFARE_INFO_NM")
#                 })
            
#             current_page += 1
#             time.sleep(0.5)
            
#         except Exception as e:
#             print(f"âŒ ëª©ë¡ ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
#             break
            
#     print(f"ğŸ‰ ì´ {len(all_services)}ê°œì˜ ì„œë¹„ìŠ¤ ëª©ë¡ì„ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤.")
#     return all_services

# def scrape_details_by_clicking_tabs(services):
#     """
#     Seleniumìœ¼ë¡œ ê° ì„œë¹„ìŠ¤ì˜ íƒ­ì„ í´ë¦­í•˜ë©° ìƒì„¸ ë‚´ìš©ì„ ìŠ¤í¬ë˜í•‘í•©ë‹ˆë‹¤.
#     """
#     print("\nâœ… [2ë‹¨ê³„] Seleniumìœ¼ë¡œ ìƒì„¸ ì •ë³´ ìŠ¤í¬ë˜í•‘ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    
#     options = webdriver.ChromeOptions()
#     options.add_experimental_option('excludeSwitches', ['enable-logging'])
#     options.add_argument('--log-level=3')
#     options.add_argument("--headless") # ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰ì„ ì›í•˜ë©´ ì´ ì¤„ì˜ ì£¼ì„ì„ í•´ì œ
#     options.add_argument("--no-sandbox")
#     options.add_argument("--disable-dev-shm-usage")
#     options.add_argument("--disable-gpu")
#     options.add_argument("window-size=1920x1080")
    
#     driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
    
#     final_results = []
#     total = len(services)
    
#     for i, service in enumerate(services):
#         service_id = service['id']
#         service_name = service['name']
        
#         if not service_id: continue
            
#         detail_url = f"https://www.bokjiro.go.kr/ssis-tbu/twataa/wlfareInfo/moveTWAT52011M.do?wlfareInfoId={service_id}"
        
#         print(f"({i+1}/{total}) ìŠ¤í¬ë˜í•‘ ì¤‘: {service_name[:30]}...")
        
#         try:
#             driver.get(detail_url)
            
#             # íŒì—… ì²˜ë¦¬
#             try:
#                 popup_close_button = WebDriverWait(driver, 3).until(EC.element_to_be_clickable((By.CSS_SELECTOR, "#research_pop .btn-close-pop")))
#                 popup_close_button.click()
#             except TimeoutException:
#                 pass
            
#             # ìŠ¤í¬ë˜í•‘í•  íƒ­ ì´ë¦„ ëª©ë¡
#             tabs_to_scrape = ["ì§€ì›ëŒ€ìƒ", "ì„œë¹„ìŠ¤ ë‚´ìš©"] # 'ì‹ ì²­ë°©ë²•' ë“± ì¶”ê°€ ê°€ëŠ¥
#             scraped_content = {"ì„œë¹„ìŠ¤ëª…": service_name}
            
#             for tab_name in tabs_to_scrape:
#                 try:
#                     # 1. íƒ­ ë²„íŠ¼ì„ ì°¾ì•„ì„œ í´ë¦­
#                     # XPathë¥¼ ì‚¬ìš©í•´ í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•˜ëŠ” <a> íƒœê·¸ë¥¼ ì°¾ìŒ
#                     tab_button = WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.XPATH, f"//a[@class='cl-text-wrapper' and contains(., '{tab_name}')]")))
#                     tab_button.click()
                    
#                     # 2. ë‚´ìš©ì´ ë¡œë”©ë  ì‹œê°„ì„ ì ì‹œ ì¤Œ (í´ë¦­ í›„ DOMì´ ë³€ê²½ë˜ëŠ” ì‹œê°„)
#                     time.sleep(0.5) 
                    
#                     # 3. ë‚´ìš©ì´ í‘œì‹œë˜ëŠ” ì»¨í…Œì´ë„ˆë¥¼ ì°¾ì•„ í…ìŠ¤íŠ¸ ì¶”ì¶œ
#                     content_container = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.CSS_SELECTOR, "div.tab-content-inner")))
#                     scraped_content[tab_name] = content_container.text.strip()
                    
#                 except Exception as tab_e:
#                     print(f"  - '{tab_name}' íƒ­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {tab_e.__class__.__name__}")
#                     scraped_content[tab_name] = "ë‚´ìš©ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ"
            
#             final_results.append(scraped_content)
            
#         except Exception as e:
#             print(f"  - í˜ì´ì§€ ì²˜ë¦¬ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {service_name} ({e.__class__.__name__})")
#             final_results.append({"ì„œë¹„ìŠ¤ëª…": service_name, "ì§€ì›ëŒ€ìƒ": "ì˜¤ë¥˜", "ì„œë¹„ìŠ¤ ë‚´ìš©": "ì˜¤ë¥˜"})
    
#     driver.quit()
#     print("ğŸ‰ ìƒì„¸ ì •ë³´ ìŠ¤í¬ë˜í•‘ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.")
#     return final_results

# def save_results(data):
#     """
#     ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ CSVì™€ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
#     """
#     if not data:
#         print("âš ï¸ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
#         return
        
#     print("\nâœ… [3ë‹¨ê³„] ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.")
    
#     # CSV íŒŒì¼ë¡œ ì €ì¥
#     try:
#         with open('bokjiro_services.csv', 'w', newline='', encoding='utf-8-sig') as f:
#             # ë™ì ìœ¼ë¡œ í•„ë“œ ì´ë¦„ì„ ì„¤ì • (ì„œë¹„ìŠ¤ëª…, ì§€ì›ëŒ€ìƒ, ì„œë¹„ìŠ¤ ë‚´ìš©, ...)
#             fieldnames = list(data[0].keys())
#             writer = csv.DictWriter(f, fieldnames=fieldnames)
#             writer.writeheader()
#             writer.writerows(data)
#         print("ğŸ’¾ CSV íŒŒì¼ ì €ì¥ ì™„ë£Œ: bokjiro_services.csv")
#     except Exception as e:
#         print(f"âŒ CSV íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
        
#     # JSON íŒŒì¼ë¡œ ì €ì¥
#     try:
#         with open('bokjiro_services.json', 'w', encoding='utf-8') as f:
#             json.dump(data, f, ensure_ascii=False, indent=4)
#         print("ğŸ’¾ JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ: bokjiro_services.json")
#     except Exception as e:
#         print(f"âŒ JSON íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")

# # --- ë©”ì¸ ì½”ë“œ ì‹¤í–‰ ---
# if __name__ == "__main__":
#     # í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ëª©ë¡ ê°œìˆ˜ ì œí•œ: services_list = get_all_service_list()[:10]
#     services_list = get_all_service_list()
    
#     if services_list:
#         detailed_data = scrape_details_by_clicking_tabs(services_list)
#         save_results(detailed_data)
        
#     print("\nâœ¨ ëª¨ë“  í¬ë¡¤ë§ ì‘ì—…ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

# import requests
# import json
# import csv
# import time
# from selenium import webdriver
# from selenium.webdriver.chrome.service import Service
# from selenium.webdriver.common.by import By
# from selenium.webdriver.support.ui import WebDriverWait
# from selenium.webdriver.support import expected_conditions as EC
# from selenium.common.exceptions import TimeoutException
# from webdriver_manager.chrome import ChromeDriverManager

# def get_all_service_list():
#     """
#     ë³µì§€ë¡œ APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì „ì²´ ì„œë¹„ìŠ¤ ëª©ë¡(ID, ì´ë¦„)ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
#     """
#     print("âœ… [1ë‹¨ê³„] ì „ì²´ ë³µì§€ ì„œë¹„ìŠ¤ ëª©ë¡ ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
#     list_url = "https://www.bokjiro.go.kr/ssis-tbu/TWAT52005M/twataa/wlfareInfo/selectWlfareInfo.do"
#     headers = {
#         'Accept': 'application/json, text/javascript, */*; q=0.01',
#         'Content-Type': 'application/json; charset=UTF-8',
#         'Referer': 'https://www.bokjiro.go.kr/ssis-tbu/twataa/wlfareInfo/moveTWAT52005M.do',
#         'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36',
#     }
    
#     # --- âœ¨ ìˆ˜ì •ëœ ë¶€ë¶„: ëˆ„ë½ë˜ì—ˆë˜ í•„ìˆ˜ ìš”ì²­ê°’ì„ ëª¨ë‘ ë³µì› ---
#     payload_template = {
#         "dmSearchParam": {
#             "page": "1", "pageUnit": "100", "onlineYn": "", "searchTerm": "", "tabId": "1", "orderBy": "date",
#             "bkjrLftmCycCd": "", "daesang": "", "period": "", "age": "", "region": "", "jjim": "",
#             "subject": "", "favoriteKeyword": "Y", "sido": "", "gungu": "", "endYn": "N"
#         },
#         "dmScr": {"curScrId": "tbu/app/twat/twata/twataa/TWAT52005M", "befScrId": ""}
#     }
#     # ---
    
#     all_services = []
#     current_page = 1
    
#     while True:
#         print(f"ğŸ“„ ëª©ë¡ {current_page}í˜ì´ì§€ë¥¼ ìš”ì²­í•©ë‹ˆë‹¤...")
#         payload_template["dmSearchParam"]["page"] = str(current_page)
        
#         try:
#             response = requests.post(list_url, headers=headers, json=payload_template)
#             response.raise_for_status()
#             data = response.json()
            
#             services_on_page = []
#             for i in range(4):
#                 services_on_page.extend(data.get(f"dsServiceList{i}", []))

#             if not services_on_page:
#                 print("âœ”ï¸ ë” ì´ìƒ ê°€ì ¸ì˜¬ ëª©ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
#                 break
            
#             for service in services_on_page:
#                 all_services.append({
#                     "id": service.get("WLFARE_INFO_ID"),
#                     "name": service.get("WLFARE_INFO_NM")
#                 })
            
#             current_page += 1
#             time.sleep(0.5)
            
#         except Exception as e:
#             print(f"âŒ ëª©ë¡ ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
#             break
            
#     print(f"ğŸ‰ ì´ {len(all_services)}ê°œì˜ ì„œë¹„ìŠ¤ ëª©ë¡ì„ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤.")
#     return all_services

# def scrape_details_by_clicking_tabs(services):
#     """
#     Seleniumìœ¼ë¡œ ê° ì„œë¹„ìŠ¤ì˜ íƒ­ì„ í´ë¦­í•˜ë©° ìƒì„¸ ë‚´ìš©ì„ ìŠ¤í¬ë˜í•‘í•©ë‹ˆë‹¤.
#     """
#     print("\nâœ… [2ë‹¨ê³„] Seleniumìœ¼ë¡œ ìƒì„¸ ì •ë³´ ìŠ¤í¬ë˜í•‘ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    
#     options = webdriver.ChromeOptions()
#     options.add_experimental_option('excludeSwitches', ['enable-logging'])
#     options.add_argument('--log-level=3')
#     # options.add_argument("--headless")
#     options.add_argument("--no-sandbox")
#     options.add_argument("--disable-dev-shm-usage")
#     options.add_argument("--disable-gpu")
#     options.add_argument("window-size=1920x1080")
    
#     driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
    
#     final_results = []
#     total = len(services)
    
#     for i, service in enumerate(services):
#         service_id = service['id']
#         service_name = service['name']
        
#         if not service_id: continue
            
#         detail_url = f"https://www.bokjiro.go.kr/ssis-tbu/twataa/wlfareInfo/moveTWAT52011M.do?wlfareInfoId={service_id}"
        
#         print(f"({i+1}/{total}) ìŠ¤í¬ë˜í•‘ ì¤‘: {service_name[:30]}...")
        
#         try:
#             driver.get(detail_url)
            
#             try:
#                 popup_close_button = WebDriverWait(driver, 3).until(EC.element_to_be_clickable((By.CSS_SELECTOR, "#research_pop .btn-close-pop")))
#                 popup_close_button.click()
#             except TimeoutException:
#                 pass
            
#             tabs_to_scrape = ["ì§€ì›ëŒ€ìƒ", "ì„œë¹„ìŠ¤ ë‚´ìš©"]
#             scraped_content = {"ì„œë¹„ìŠ¤ëª…": service_name}
            
#             for tab_name in tabs_to_scrape:
#                 try:
#                     tab_button = WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.XPATH, f"//a[@class='cl-text-wrapper' and contains(., '{tab_name}')]")))
#                     tab_button.click()
#                     time.sleep(0.5) 
#                     content_container = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.CSS_SELECTOR, "div.tab-content-inner")))
#                     scraped_content[tab_name] = content_container.text.strip()
#                 except Exception as tab_e:
#                     print(f"  - '{tab_name}' íƒ­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {tab_e.__class__.__name__}")
#                     scraped_content[tab_name] = "ë‚´ìš©ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ"
            
#             final_results.append(scraped_content)
            
#         except Exception as e:
#             print(f"  - í˜ì´ì§€ ì²˜ë¦¬ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {service_name} ({e.__class__.__name__})")
#             final_results.append({"ì„œë¹„ìŠ¤ëª…": service_name, "ì§€ì›ëŒ€ìƒ": "ì˜¤ë¥˜", "ì„œë¹„ìŠ¤ ë‚´ìš©": "ì˜¤ë¥˜"})
    
#     driver.quit()
#     print("ğŸ‰ ìƒì„¸ ì •ë³´ ìŠ¤í¬ë˜í•‘ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.")
#     return final_results

# def save_results(data):
#     """
#     ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ CSVì™€ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
#     """
#     if not data:
#         print("âš ï¸ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
#         return
        
#     print("\nâœ… [3ë‹¨ê³„] ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.")
    
#     try:
#         with open('bokjiro_services.csv', 'w', newline='', encoding='utf-8-sig') as f:
#             fieldnames = list(data[0].keys())
#             writer = csv.DictWriter(f, fieldnames=fieldnames)
#             writer.writeheader()
#             writer.writerows(data)
#         print("ğŸ’¾ CSV íŒŒì¼ ì €ì¥ ì™„ë£Œ: bokjiro_services.csv")
#     except Exception as e:
#         print(f"âŒ CSV íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
        
#     try:
#         with open('bokjiro_services.json', 'w', encoding='utf-8') as f:
#             json.dump(data, f, ensure_ascii=False, indent=4)
#         print("ğŸ’¾ JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ: bokjiro_services.json")
#     except Exception as e:
#         print(f"âŒ JSON íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")

# # --- ë©”ì¸ ì½”ë“œ ì‹¤í–‰ ---
# # --- ë©”ì¸ ì½”ë“œ ì‹¤í–‰ ---
# if __name__ == "__main__":
#     # í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì „ì²´ ëª©ë¡ ì¤‘ 10ê°œë§Œ ì˜ë¼ì„œ ì‚¬ìš©
#     services_list = get_all_service_list()[:10]
    
#     if services_list:
#         detailed_data = scrape_details_by_clicking_tabs(services_list)
#         save_results(detailed_data)
        
#     print("\nâœ¨ ëª¨ë“  í¬ë¡¤ë§ ì‘ì—…ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

# import requests
# import json
# import csv
# import time
# from selenium import webdriver
# from selenium.webdriver.chrome.service import Service
# from selenium.webdriver.common.by import By
# from selenium.webdriver.support.ui import WebDriverWait
# from selenium.webdriver.support import expected_conditions as EC
# from selenium.common.exceptions import TimeoutException
# from webdriver_manager.chrome import ChromeDriverManager

# # ì›í•˜ëŠ” ê°œìˆ˜ë§Œí¼ë§Œ ê°€ì ¸ì˜¤ë„ë¡ limit ì¸ì ì¶”ê°€
# def get_all_service_list(limit=None):
#     """
#     ë³µì§€ë¡œ APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì„œë¹„ìŠ¤ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
#     limitì´ ì§€ì •ë˜ë©´ í•´ë‹¹ ê°œìˆ˜ë§Œí¼ë§Œ ê°€ì ¸ì˜¤ê³  ì¤‘ë‹¨í•©ë‹ˆë‹¤.
#     """
#     print("âœ… [1ë‹¨ê³„] ë³µì§€ ì„œë¹„ìŠ¤ ëª©ë¡ ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
#     # ... (URL, headers, payload ë“± ë‹¤ë¥¸ ë¶€ë¶„ì€ ë™ì¼) ...
#     list_url = "https://www.bokjiro.go.kr/ssis-tbu/TWAT52005M/twataa/wlfareInfo/selectWlfareInfo.do"
#     headers = {'Accept': 'application/json, text/javascript, */*; q=0.01', 'Content-Type': 'application/json; charset=UTF-8', 'Referer': 'https://www.bokjiro.go.kr/ssis-tbu/twataa/wlfareInfo/moveTWAT52005M.do', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36',}
#     payload_template = {"dmSearchParam": {"page": "1", "pageUnit": "100", "onlineYn": "", "searchTerm": "", "tabId": "1", "orderBy": "date", "bkjrLftmCycCd": "", "daesang": "", "period": "", "age": "", "region": "", "jjim": "", "subject": "", "favoriteKeyword": "Y", "sido": "", "gungu": "", "endYn": "N"}, "dmScr": {"curScrId": "tbu/app/twat/twata/twataa/TWAT52005M", "befScrId": ""}}
    
#     all_services = []
#     current_page = 1
    
#     while True:
#         print(f"ğŸ“„ ëª©ë¡ {current_page}í˜ì´ì§€ë¥¼ ìš”ì²­í•©ë‹ˆë‹¤...")
#         payload_template["dmSearchParam"]["page"] = str(current_page)
        
#         try:
#             response = requests.post(list_url, headers=headers, json=payload_template)
#             response.raise_for_status()
#             data = response.json()
            
#             services_on_page = []
#             for i in range(4):
#                 services_on_page.extend(data.get(f"dsServiceList{i}", []))

#             if not services_on_page:
#                 print("âœ”ï¸ ë” ì´ìƒ ê°€ì ¸ì˜¬ ëª©ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
#                 break
            
#             for service in services_on_page:
#                 all_services.append({"id": service.get("WLFARE_INFO_ID"), "name": service.get("WLFARE_INFO_NM")})
            
#             # --- âœ¨ ìˆ˜ì •ëœ ë¶€ë¶„ ì‹œì‘ âœ¨ ---
#             # ë§Œì•½ limitì´ ìˆê³ , ìˆ˜ì§‘í•œ ê°œìˆ˜ê°€ limitì„ ë„˜ìœ¼ë©´ ë°˜ë³µ ì¤‘ë‹¨
#             if limit and len(all_services) >= limit:
#                 print(f"âœ”ï¸ ìš”ì²­í•˜ì‹  {limit}ê°œ ì´ìƒì˜ ëª©ë¡ì„ ìˆ˜ì§‘í•˜ì—¬ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
#                 break
#             # --- âœ¨ ìˆ˜ì •ëœ ë¶€ë¶„ ë âœ¨ ---
            
#             current_page += 1
#             time.sleep(0.5)
            
#         except Exception as e:
#             print(f"âŒ ëª©ë¡ ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
#             break
    
#     # ìµœì¢…ì ìœ¼ë¡œ limit ê°œìˆ˜ë§Œí¼ë§Œ ì˜ë¼ì„œ ë°˜í™˜
#     if limit:
#         all_services = all_services[:limit]

#     print(f"ğŸ‰ ì´ {len(all_services)}ê°œì˜ ì„œë¹„ìŠ¤ ëª©ë¡ì„ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤.")
#     return all_services

# # scrape_details_by_clicking_tabs í•¨ìˆ˜ì™€ save_results í•¨ìˆ˜ëŠ” ë³€ê²½ ì—†ìŠµë‹ˆë‹¤.
# def scrape_details_by_clicking_tabs(services):
#     print("\nâœ… [2ë‹¨ê³„] Seleniumìœ¼ë¡œ ìƒì„¸ ì •ë³´ ìŠ¤í¬ë˜í•‘ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
#     options = webdriver.ChromeOptions()
#     options.add_experimental_option('excludeSwitches', ['enable-logging'])
#     options.add_argument('--log-level=3')
#     # options.add_argument("--headless")
#     options.add_argument("--no-sandbox")
#     options.add_argument("--disable-dev-shm-usage")
#     options.add_argument("--disable-gpu")
#     options.add_argument("window-size=1920x1080")
#     driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
#     final_results = []
#     total = len(services)
#     for i, service in enumerate(services):
#         service_id, service_name = service['id'], service['name']
#         if not service_id: continue
#         detail_url = f"https://www.bokjiro.go.kr/ssis-tbu/twataa/wlfareInfo/moveTWAT52011M.do?wlfareInfoId={service_id}"
#         print(f"({i+1}/{total}) ìŠ¤í¬ë˜í•‘ ì¤‘: {service_name[:30]}...")
#         try:
#             driver.get(detail_url)
#             try:
#                 WebDriverWait(driver, 3).until(EC.element_to_be_clickable((By.CSS_SELECTOR, "#research_pop .btn-close-pop"))).click()
#             except TimeoutException:
#                 pass
#             tabs_to_scrape = ["ì§€ì›ëŒ€ìƒ", "ì„œë¹„ìŠ¤ ë‚´ìš©"]
#             scraped_content = {"ì„œë¹„ìŠ¤ëª…": service_name}
#             for tab_name in tabs_to_scrape:
#                 try:
#                     WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.XPATH, f"//a[@class='cl-text-wrapper' and contains(., '{tab_name}')]"))).click()
#                     time.sleep(0.5)
#                     content_container = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.CSS_SELECTOR, "div.tab-content-inner")))
#                     scraped_content[tab_name] = content_container.text.strip()
#                 except Exception:
#                     scraped_content[tab_name] = "ë‚´ìš©ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ"
#             final_results.append(scraped_content)
#         except Exception:
#             final_results.append({"ì„œë¹„ìŠ¤ëª…": service_name, "ì§€ì›ëŒ€ìƒ": "ì˜¤ë¥˜", "ì„œë¹„ìŠ¤ ë‚´ìš©": "ì˜¤ë¥˜"})
#     driver.quit()
#     print("ğŸ‰ ìƒì„¸ ì •ë³´ ìŠ¤í¬ë˜í•‘ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.")
#     return final_results
# def save_results(data):
#     if not data: print("âš ï¸ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."); return
#     print("\nâœ… [3ë‹¨ê³„] ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.")
#     try:
#         with open('bokjiro_services.csv', 'w', newline='', encoding='utf-8-sig') as f:
#             fieldnames = list(data[0].keys()); writer = csv.DictWriter(f, fieldnames=fieldnames); writer.writeheader(); writer.writerows(data)
#         print("ğŸ’¾ CSV íŒŒì¼ ì €ì¥ ì™„ë£Œ: bokjiro_services.csv")
#     except Exception as e: print(f"âŒ CSV íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
#     try:
#         with open('bokjiro_services.json', 'w', encoding='utf-8') as f: json.dump(data, f, ensure_ascii=False, indent=4)
#         print("ğŸ’¾ JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ: bokjiro_services.json")
#     except Exception as e: print(f"âŒ JSON íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")

# # --- ë©”ì¸ ì½”ë“œ ì‹¤í–‰ ---
# if __name__ == "__main__":
#     # ğŸ§ª í…ŒìŠ¤íŠ¸: 10ê°œë§Œ ê°€ì ¸ì˜¤ê¸°
#     services_list = get_all_service_list(limit=10)
    
#     # ğŸš€ ì „ì²´ ì‹¤í–‰: ëª¨ë“  ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
#     # services_list = get_all_service_list()
    
#     if services_list:
#         detailed_data = scrape_details_by_clicking_tabs(services_list)
#         save_results(detailed_data)
        
#     print("\nâœ¨ ëª¨ë“  í¬ë¡¤ë§ ì‘ì—…ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

# import requests
# import json
# import csv
# import time
# from selenium import webdriver
# from selenium.webdriver.chrome.service import Service
# from selenium.webdriver.common.by import By
# from selenium.webdriver.support.ui import WebDriverWait
# from selenium.webdriver.support import expected_conditions as EC
# from selenium.common.exceptions import TimeoutException
# from webdriver_manager.chrome import ChromeDriverManager

# def get_all_service_list(limit=None):
#     """
#     ë³µì§€ë¡œ APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì„œë¹„ìŠ¤ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
#     limitì´ ì§€ì •ë˜ë©´ í•´ë‹¹ ê°œìˆ˜ë§Œí¼ë§Œ ê°€ì ¸ì˜¤ê³  ì¤‘ë‹¨í•˜ì—¬ í…ŒìŠ¤íŠ¸ ì†ë„ë¥¼ ë†’ì…ë‹ˆë‹¤.
#     """
#     print("âœ… [1ë‹¨ê³„] ë³µì§€ ì„œë¹„ìŠ¤ ëª©ë¡ ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
#     list_url = "https://www.bokjiro.go.kr/ssis-tbu/TWAT52005M/twataa/wlfareInfo/selectWlfareInfo.do"
#     headers = {
#         'Accept': 'application/json, text/javascript, */*; q=0.01',
#         'Content-Type': 'application/json; charset=UTF-8',
#         'Referer': 'https://www.bokjiro.go.kr/ssis-tbu/twataa/wlfareInfo/moveTWAT52005M.do',
#         'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36',
#     }
#     payload_template = {
#         "dmSearchParam": {
#             "page": "1", "pageUnit": "100", "onlineYn": "", "searchTerm": "", "tabId": "1", "orderBy": "date",
#             "bkjrLftmCycCd": "", "daesang": "", "period": "", "age": "", "region": "", "jjim": "",
#             "subject": "", "favoriteKeyword": "Y", "sido": "", "gungu": "", "endYn": "N"
#         },
#         "dmScr": {"curScrId": "tbu/app/twat/twata/twataa/TWAT52005M", "befScrId": ""}
#     }
    
#     all_services = []
#     current_page = 1
    
#     while True:
#         # ë£¨í”„ê°€ limitì„ ë„˜ì§€ ì•Šë„ë¡ ë°©ì§€ (í•„ìˆ˜ëŠ” ì•„ë‹ˆë‚˜ ì¶”ê°€ì ì¸ ì•ˆì „ì¥ì¹˜)
#         if limit and len(all_services) >= limit:
#             break
            
#         print(f"ğŸ“„ ëª©ë¡ {current_page}í˜ì´ì§€ë¥¼ ìš”ì²­í•©ë‹ˆë‹¤...")
#         payload_template["dmSearchParam"]["page"] = str(current_page)
        
#         try:
#             response = requests.post(list_url, headers=headers, json=payload_template)
#             response.raise_for_status()
#             data = response.json()
            
#             services_on_page = []
#             for i in range(4): # dsServiceList0 ~ dsServiceList3 í™•ì¸
#                 services_on_page.extend(data.get(f"dsServiceList{i}", []))

#             if not services_on_page:
#                 print("âœ”ï¸ ë” ì´ìƒ ê°€ì ¸ì˜¬ ëª©ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
#                 break
            
#             for service in services_on_page:
#                 all_services.append({"id": service.get("WLFARE_INFO_ID"), "name": service.get("WLFARE_INFO_NM")})
            
#             # limitì´ ì§€ì •ë˜ì—ˆê³ , ìˆ˜ì§‘í•œ ê°œìˆ˜ê°€ limitì„ ë„˜ìœ¼ë©´ ë°˜ë³µ ì¤‘ë‹¨
#             if limit and len(all_services) >= limit:
#                 print(f"âœ”ï¸ ìš”ì²­í•˜ì‹  {limit}ê°œ ì´ìƒì˜ ëª©ë¡ì„ ìˆ˜ì§‘í•˜ì—¬ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
#                 break
            
#             current_page += 1
#             time.sleep(0.5)
            
#         except Exception as e:
#             print(f"âŒ ëª©ë¡ ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
#             break
    
#     # ìµœì¢…ì ìœ¼ë¡œ limit ê°œìˆ˜ë§Œí¼ë§Œ ì˜ë¼ì„œ ë°˜í™˜
#     if limit:
#         all_services = all_services[:limit]

#     print(f"ğŸ‰ ì´ {len(all_services)}ê°œì˜ ì„œë¹„ìŠ¤ ëª©ë¡ì„ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤.")
#     return all_services

# def scrape_details_by_clicking_tabs(services):
#     """
#     Seleniumìœ¼ë¡œ ê° ì„œë¹„ìŠ¤ì˜ íƒ­ì„ í´ë¦­í•˜ë©° ìƒì„¸ ë‚´ìš©ì„ ìŠ¤í¬ë˜í•‘í•©ë‹ˆë‹¤.
#     """
#     print("\nâœ… [2ë‹¨ê³„] Seleniumìœ¼ë¡œ ìƒì„¸ ì •ë³´ ìŠ¤í¬ë˜í•‘ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    
#     options = webdriver.ChromeOptions()
#     options.add_experimental_option('excludeSwitches', ['enable-logging'])
#     options.add_argument('--log-level=3')
#     # options.add_argument("--headless") # ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰ì„ ì›í•˜ë©´ ì´ ì¤„ì˜ ì£¼ì„ì„ í•´ì œí•˜ì„¸ìš”.
#     options.add_argument("--no-sandbox")
#     options.add_argument("--disable-dev-shm-usage")
#     options.add_argument("--disable-gpu")
#     options.add_argument("window-size=1920x1080")
    
#     driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
    
#     final_results = []
#     total = len(services)
    
#     for i, service in enumerate(services):
#         service_id = service['id']
#         service_name = service['name']
        
#         if not service_id: continue
            
#         detail_url = f"https://www.bokjiro.go.kr/ssis-tbu/twataa/wlfareInfo/moveTWAT52011M.do?wlfareInfoId={service_id}"
        
#         print(f"({i+1}/{total}) ìŠ¤í¬ë˜í•‘ ì¤‘: {service_name[:30]}...")
        
#         try:
#             driver.get(detail_url)
            
#             # íŒì—… ì²˜ë¦¬ (3ì´ˆë§Œ ê¸°ë‹¤ë¦¼)
#             try:
#                 popup_close_button = WebDriverWait(driver, 3).until(EC.element_to_be_clickable((By.CSS_SELECTOR, "#research_pop .btn-close-pop")))
#                 popup_close_button.click()
#             except TimeoutException:
#                 pass # íŒì—…ì´ ì—†ìœ¼ë©´ ê·¸ëƒ¥ ë„˜ì–´ê°
            
#             # ìŠ¤í¬ë˜í•‘í•  íƒ­ ì´ë¦„ ëª©ë¡
#             tabs_to_scrape = ["ì§€ì›ëŒ€ìƒ", "ì„œë¹„ìŠ¤ ë‚´ìš©"]
#             scraped_content = {"ì„œë¹„ìŠ¤ëª…": service_name}
            
#             for tab_name in tabs_to_scrape:
#                 try:
#                     # 1. íƒ­ ë²„íŠ¼ì„ ì°¾ì•„ì„œ í´ë¦­
#                     tab_button = WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.XPATH, f"//a[@class='cl-text-wrapper' and contains(., '{tab_name}')]")))
#                     tab_button.click()
                    
#                     # 2. ë‚´ìš©ì´ ë¡œë”©ë  ì‹œê°„ì„ ì ì‹œ ì¤Œ
#                     time.sleep(0.5) 
                    
#                     # 3. ë‚´ìš©ì´ í‘œì‹œë˜ëŠ” ì»¨í…Œì´ë„ˆë¥¼ ì°¾ì•„ í…ìŠ¤íŠ¸ ì¶”ì¶œ
#                     content_container = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.CSS_SELECTOR, "div.tab-content-inner")))
#                     scraped_content[tab_name] = content_container.text.strip()
                    
#                 except Exception:
#                     scraped_content[tab_name] = "ë‚´ìš©ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ"
            
#             final_results.append(scraped_content)
            
#         except Exception as e:
#             print(f"  - í˜ì´ì§€ ì²˜ë¦¬ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {service_name} ({e.__class__.__name__})")
#             final_results.append({"ì„œë¹„ìŠ¤ëª…": service_name, "ì§€ì›ëŒ€ìƒ": "ì˜¤ë¥˜", "ì„œë¹„ìŠ¤ ë‚´ìš©": "ì˜¤ë¥˜"})
    
#     driver.quit()
#     print("ğŸ‰ ìƒì„¸ ì •ë³´ ìŠ¤í¬ë˜í•‘ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.")
#     return final_results

# def save_results(data):
#     """
#     ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ CSVì™€ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
#     """
#     if not data:
#         print("âš ï¸ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
#         return
        
#     print("\nâœ… [3ë‹¨ê³„] ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.")
    
#     try:
#         with open('bokjiro_services.csv', 'w', newline='', encoding='utf-8-sig') as f:
#             fieldnames = list(data[0].keys())
#             writer = csv.DictWriter(f, fieldnames=fieldnames)
#             writer.writeheader()
#             writer.writerows(data)
#         print("ğŸ’¾ CSV íŒŒì¼ ì €ì¥ ì™„ë£Œ: bokjiro_services.csv")
#     except Exception as e:
#         print(f"âŒ CSV íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
        
#     try:
#         with open('bokjiro_services.json', 'w', encoding='utf-8') as f:
#             json.dump(data, f, ensure_ascii=False, indent=4)
#         print("ğŸ’¾ JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ: bokjiro_services.json")
#     except Exception as e:
#         print(f"âŒ JSON íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")

# # --- ë©”ì¸ ì½”ë“œ ì‹¤í–‰ ---
# if __name__ == "__main__":
    
#     # ğŸ§ª í…ŒìŠ¤íŠ¸: 10ê°œë§Œ ê°€ì ¸ì˜¤ë ¤ë©´ ì•„ë˜ ì¤„ì˜ ì£¼ì„ì„ í•´ì œí•˜ì„¸ìš”.
#     # services_list = get_all_service_list(limit=10)
    
#     # ğŸš€ ì „ì²´ ì‹¤í–‰: ëª¨ë“  ëª©ë¡ì„ ê°€ì ¸ì˜¤ë ¤ë©´ ì•„ë˜ ì¤„ì„ ì‚¬ìš©í•˜ì„¸ìš”.
#     services_list = get_all_service_list()
    
#     if services_list:
#         detailed_data = scrape_details_by_clicking_tabs(services_list)
#         save_results(detailed_data)
        
#     print("\nâœ¨ ëª¨ë“  í¬ë¡¤ë§ ì‘ì—…ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

# import requests
# import json
# import csv
# import time
# from selenium import webdriver
# from selenium.webdriver.chrome.service import Service
# from selenium.webdriver.common.by import By
# from selenium.webdriver.support.ui import WebDriverWait
# from selenium.webdriver.support import expected_conditions as EC
# from selenium.common.exceptions import TimeoutException
# from webdriver_manager.chrome import ChromeDriverManager

# def get_all_service_list(limit=None):
#     """
#     ë³µì§€ë¡œ APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì„œë¹„ìŠ¤ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
#     limitì´ ì§€ì •ë˜ë©´ í•´ë‹¹ ê°œìˆ˜ë§Œí¼ë§Œ ê°€ì ¸ì˜¤ê³  ì¤‘ë‹¨í•˜ì—¬ í…ŒìŠ¤íŠ¸ ì†ë„ë¥¼ ë†’ì…ë‹ˆë‹¤.
#     """
#     print("âœ… [1ë‹¨ê³„] ë³µì§€ ì„œë¹„ìŠ¤ ëª©ë¡ ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
#     list_url = "https://www.bokjiro.go.kr/ssis-tbu/TWAT52005M/twataa/wlfareInfo/selectWlfareInfo.do"
#     headers = {
#         'Accept': 'application/json, text/javascript, */*; q=0.01',
#         'Content-Type': 'application/json; charset=UTF-8',
#         'Referer': 'https://www.bokjiro.go.kr/ssis-tbu/twataa/wlfareInfo/moveTWAT52005M.do',
#         'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36',
#     }
#     payload_template = {
#         "dmSearchParam": {
#             "page": "1", "pageUnit": "100", "onlineYn": "", "searchTerm": "", "tabId": "1", "orderBy": "date",
#             "bkjrLftmCycCd": "", "daesang": "", "period": "", "age": "", "region": "", "jjim": "",
#             "subject": "", "favoriteKeyword": "Y", "sido": "", "gungu": "", "endYn": "N"
#         },
#         "dmScr": {"curScrId": "tbu/app/twat/twata/twataa/TWAT52005M", "befScrId": ""}
#     }
    
#     all_services = []
#     current_page = 1
    
#     while True:
#         if limit and len(all_services) >= limit:
#             break
            
#         print(f"ğŸ“„ ëª©ë¡ {current_page}í˜ì´ì§€ë¥¼ ìš”ì²­í•©ë‹ˆë‹¤...")
#         payload_template["dmSearchParam"]["page"] = str(current_page)
        
#         try:
#             response = requests.post(list_url, headers=headers, json=payload_template)
#             response.raise_for_status()
#             data = response.json()
            
#             services_on_page = []
#             for i in range(4):
#                 services_on_page.extend(data.get(f"dsServiceList{i}", []))

#             if not services_on_page:
#                 print("âœ”ï¸ ë” ì´ìƒ ê°€ì ¸ì˜¬ ëª©ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
#                 break
            
#             for service in services_on_page:
#                 all_services.append({"id": service.get("WLFARE_INFO_ID"), "name": service.get("WLFARE_INFO_NM")})
            
#             if limit and len(all_services) >= limit:
#                 print(f"âœ”ï¸ ìš”ì²­í•˜ì‹  {limit}ê°œ ì´ìƒì˜ ëª©ë¡ì„ ìˆ˜ì§‘í•˜ì—¬ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
#                 break
            
#             current_page += 1
#             time.sleep(0.5)
            
#         except Exception as e:
#             print(f"âŒ ëª©ë¡ ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
#             break
    
#     if limit:
#         all_services = all_services[:limit]

#     print(f"ğŸ‰ ì´ {len(all_services)}ê°œì˜ ì„œë¹„ìŠ¤ ëª©ë¡ì„ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤.")
#     return all_services

# def scrape_details_by_clicking_tabs(services):
#     """
#     Seleniumìœ¼ë¡œ ê° ì„œë¹„ìŠ¤ì˜ íƒ­ì„ í´ë¦­í•˜ë©° ìƒì„¸ ë‚´ìš©ì„ ìŠ¤í¬ë˜í•‘í•©ë‹ˆë‹¤.
#     """
#     print("\nâœ… [2ë‹¨ê³„] Seleniumìœ¼ë¡œ ìƒì„¸ ì •ë³´ ìŠ¤í¬ë˜í•‘ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    
#     options = webdriver.ChromeOptions()
#     options.add_experimental_option('excludeSwitches', ['enable-logging'])
#     options.add_argument('--log-level=3')
#     # options.add_argument("--headless") # ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰ì„ ì›í•˜ë©´ ì´ ì¤„ì˜ ì£¼ì„ì„ í•´ì œí•˜ì„¸ìš”.
#     options.add_argument("--no-sandbox")
#     options.add_argument("--disable-dev-shm-usage")
#     options.add_argument("--disable-gpu")
#     options.add_argument("window-size=1920x1080")
    
#     driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
    
#     final_results = []
#     total = len(services)
    
#     for i, service in enumerate(services):
#         service_id, service_name = service['id'], service['name']
#         if not service_id: continue
            
#         detail_url = f"https://www.bokjiro.go.kr/ssis-tbu/twataa/wlfareInfo/moveTWAT52011M.do?wlfareInfoId={service_id}"
#         print(f"({i+1}/{total}) ìŠ¤í¬ë˜í•‘ ì¤‘: {service_name[:30]}...")
        
#         try:
#             driver.get(detail_url)
            
#             try:
#                 popup_close_button = WebDriverWait(driver, 3).until(EC.element_to_be_clickable((By.CSS_SELECTOR, "#research_pop .btn-close-pop")))
#                 popup_close_button.click()
#             except TimeoutException:
#                 pass
            
#             tabs_to_scrape = ["ì§€ì›ëŒ€ìƒ", "ì„œë¹„ìŠ¤ ë‚´ìš©"]
#             scraped_content = {"ì„œë¹„ìŠ¤ëª…": service_name}
            
#             for tab_name in tabs_to_scrape:
#                 try:
#                     tab_button = WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.XPATH, f"//a[@class='cl-text-wrapper' and contains(., '{tab_name}')]")))
#                     tab_button.click()
#                     time.sleep(0.5)
#                     content_container = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.CSS_SELECTOR, "div.tab-content-inner")))
#                     scraped_content[tab_name] = content_container.text.strip()
#                 except Exception:
#                     scraped_content[tab_name] = "ë‚´ìš©ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ"
            
#             final_results.append(scraped_content)
            
#         except Exception as e:
#             print(f"  - í˜ì´ì§€ ì²˜ë¦¬ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {service_name} ({e.__class__.__name__})")
#             final_results.append({"ì„œë¹„ìŠ¤ëª…": service_name, "ì§€ì›ëŒ€ìƒ": "ì˜¤ë¥˜", "ì„œë¹„ìŠ¤ ë‚´ìš©": "ì˜¤ë¥˜"})
    
#     driver.quit()
#     print("ğŸ‰ ìƒì„¸ ì •ë³´ ìŠ¤í¬ë˜í•‘ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.")
#     return final_results

# def save_results(data):
#     """
#     ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ CSVì™€ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
#     """
#     if not data:
#         print("âš ï¸ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
#         return
        
#     print("\nâœ… [3ë‹¨ê³„] ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.")
    
#     try:
#         with open('bokjiro_services.csv', 'w', newline='', encoding='utf-8-sig') as f:
#             fieldnames = list(data[0].keys())
#             writer = csv.DictWriter(f, fieldnames=fieldnames)
#             writer.writeheader()
#             writer.writerows(data)
#         print("ğŸ’¾ CSV íŒŒì¼ ì €ì¥ ì™„ë£Œ: bokjiro_services.csv")
#     except Exception as e:
#         print(f"âŒ CSV íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
        
#     try:
#         with open('bokjiro_services.json', 'w', encoding='utf-8') as f:
#             json.dump(data, f, ensure_ascii=False, indent=4)
#         print("ğŸ’¾ JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ: bokjiro_services.json")
#     except Exception as e:
#         print(f"âŒ JSON íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")

# # --- ë©”ì¸ ì½”ë“œ ì‹¤í–‰ ---
# if __name__ == "__main__":
    
#     # ğŸ§ª 10ê°œë§Œ í…ŒìŠ¤íŠ¸í•˜ë ¤ë©´ ì•„ë˜ ì¤„ì„ ì‚¬ìš©í•˜ì„¸ìš”.
#     services_list = get_all_service_list(limit=10)
    
#     # ğŸš€ ì „ì²´ ëª©ë¡ì„ ê°€ì ¸ì˜¤ë ¤ë©´ ìœ„ ì¤„ì„ ì£¼ì„ ì²˜ë¦¬(#)í•˜ê³  ì•„ë˜ ì¤„ì˜ ì£¼ì„ì„ í•´ì œí•˜ì„¸ìš”.
#     # services_list = get_all_service_list()
    
#     if services_list:
#         detailed_data = scrape_details_by_clicking_tabs(services_list)
#         save_results(detailed_data)
        
#     print("\nâœ¨ ëª¨ë“  í¬ë¡¤ë§ ì‘ì—…ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

# import requests
# import json
# import csv
# import time
# from selenium import webdriver
# from selenium.webdriver.chrome.service import Service
# from selenium.webdriver.common.by import By
# from selenium.webdriver.support.ui import WebDriverWait
# from selenium.webdriver.support import expected_conditions as EC
# from selenium.common.exceptions import TimeoutException
# from webdriver_manager.chrome import ChromeDriverManager


# def get_all_service_list(limit=None):
#     """
#     ë³µì§€ë¡œ APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì„œë¹„ìŠ¤ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
#     limitì´ ì§€ì •ë˜ë©´ í•´ë‹¹ ê°œìˆ˜ë§Œí¼ë§Œ ê°€ì ¸ì˜µë‹ˆë‹¤.
#     """
#     print("âœ… [1ë‹¨ê³„] ë³µì§€ ì„œë¹„ìŠ¤ ëª©ë¡ ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
#     list_url = "https://www.bokjiro.go.kr/ssis-tbu/TWAT52005M/twataa/wlfareInfo/selectWlfareInfo.do"
#     headers = {
#         'Accept': 'application/json, text/javascript, */*; q=0.01',
#         'Content-Type': 'application/json; charset=UTF-8',
#         'Referer': 'https://www.bokjiro.go.kr/ssis-tbu/twataa/wlfareInfo/moveTWAT52005M.do',
#         'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36',
#     }
#     payload_template = {
#         "dmSearchParam": {
#             "page": "1", "pageUnit": "100", "onlineYn": "", "searchTerm": "", "tabId": "1", "orderBy": "date",
#             "bkjrLftmCycCd": "", "daesang": "", "period": "", "age": "", "region": "", "jjim": "",
#             "subject": "", "favoriteKeyword": "Y", "sido": "", "gungu": "", "endYn": "N"
#         },
#         "dmScr": {"curScrId": "tbu/app/twat/twata/twataa/TWAT52005M", "befScrId": ""}
#     }
    
#     all_services = []
#     current_page = 1
    
#     while True:
#         if limit and len(all_services) >= limit:
#             break
            
#         print(f"ğŸ“„ ëª©ë¡ {current_page}í˜ì´ì§€ë¥¼ ìš”ì²­í•©ë‹ˆë‹¤...")
#         payload_template["dmSearchParam"]["page"] = str(current_page)
        
#         try:
#             response = requests.post(list_url, headers=headers, json=payload_template)
#             response.raise_for_status()
#             data = response.json()
            
#             services_on_page = []
#             for i in range(4):
#                 services_on_page.extend(data.get(f"dsServiceList{i}", []))

#             if not services_on_page:
#                 print("âœ”ï¸ ë” ì´ìƒ ê°€ì ¸ì˜¬ ëª©ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
#                 break
            
#             for service in services_on_page:
#                 all_services.append({
#                     "id": service.get("WLFARE_INFO_ID"),
#                     "name": service.get("WLFARE_INFO_NM")
#                 })
            
#             if limit and len(all_services) >= limit:
#                 print(f"âœ”ï¸ ìš”ì²­í•˜ì‹  {limit}ê°œ ì´ìƒì˜ ëª©ë¡ì„ ìˆ˜ì§‘í•˜ì—¬ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
#                 break
            
#             current_page += 1
#             time.sleep(0.5)
            
#         except Exception as e:
#             print(f"âŒ ëª©ë¡ ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
#             break
    
#     if limit:
#         all_services = all_services[:limit]

#     print(f"ğŸ‰ ì´ {len(all_services)}ê°œì˜ ì„œë¹„ìŠ¤ ëª©ë¡ì„ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤.")
#     return all_services


# def scrape_details_by_clicking_tabs(services):
#     """
#     Seleniumìœ¼ë¡œ ê° ì„œë¹„ìŠ¤ì˜ íƒ­ì„ í´ë¦­í•˜ë©° ìƒì„¸ ë‚´ìš©ì„ ìŠ¤í¬ë˜í•‘í•©ë‹ˆë‹¤.
#     """
#     print("\nâœ… [2ë‹¨ê³„] Seleniumìœ¼ë¡œ ìƒì„¸ ì •ë³´ ìŠ¤í¬ë˜í•‘ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    
#     options = webdriver.ChromeOptions()
#     options.add_experimental_option('excludeSwitches', ['enable-logging'])
#     options.add_argument('--log-level=3')
#     options.add_argument("--headless")  # ğŸ‘‰ ë¸Œë¼ìš°ì € ì°½ ìˆ¨ê¹€ ì‹¤í–‰
#     options.add_argument("--no-sandbox")
#     options.add_argument("--disable-dev-shm-usage")
#     options.add_argument("--disable-gpu")
#     options.add_argument("window-size=1920x1080")
    
#     driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
    
#     final_results = []
#     total = len(services)
    
#     for i, service in enumerate(services):
#         service_id, service_name = service['id'], service['name']
#         if not service_id: 
#             continue
            
#         detail_url = (
#             f"https://www.bokjiro.go.kr/ssis-tbu/twataa/wlfareInfo/"
#             f"moveTWAT52011M.do?wlfareInfoId={service_id}&wlfareInfoReldBztpCd=01"
#         )
#         print(f"({i+1}/{total}) ìŠ¤í¬ë˜í•‘ ì¤‘: {service_name[:30]}...")
        
#         try:
#             driver.get(detail_url)
            
#             # íŒì—… ë‹«ê¸° (ìˆì„ ê²½ìš°)
#             try:
#                 popup_close_button = WebDriverWait(driver, 3).until(
#                     EC.element_to_be_clickable((By.CSS_SELECTOR, "#research_pop .btn-close-pop"))
#                 )
#                 popup_close_button.click()
#             except TimeoutException:
#                 pass
            
#             # ê¸ì–´ì˜¬ íƒ­ ì´ë¦„ë“¤
#             tabs_to_scrape = ["ì§€ì›ëŒ€ìƒ", "ì„œë¹„ìŠ¤ ë‚´ìš©", "í•„ìš”ì„œë¥˜"]
#             scraped_content = {"ì„œë¹„ìŠ¤ëª…": service_name}
            
#             for tab_name in tabs_to_scrape:
#                 try:
#                     # íƒ­ ë²„íŠ¼ í´ë¦­
#                     tab_button = WebDriverWait(driver, 15).until(
#                         EC.element_to_be_clickable((
#                             By.XPATH, f"//a[contains(@class, 'cl-text-wrapper')][.//div[text()='{tab_name}']]"
#                         ))
#                     )
#                     tab_button.click()
#                     time.sleep(0.7)
                    
#                     # ë³¸ë¬¸ ì»¨í…Œì´ë„ˆ ì°¾ê¸°
#                     content_container = WebDriverWait(driver, 15).until(
#                         EC.presence_of_element_located((By.CSS_SELECTOR, "div.bokjiConts"))
#                     )
#                     WebDriverWait(driver,15).untill(
#                         lambda d: content_container.text.strip() != ""
#                     )
                    
#                     scraped_content[tab_name] = content_container.text.strip()
#                 except Exception as e:
#                     scraped_content[tab_name] = f"ë‚´ìš©ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ ({type(e).__name__})"
            
#             final_results.append(scraped_content)
            
#         except Exception as e:
#             print(f"  - í˜ì´ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {service_name} ({e.__class__.__name__})")
#             final_results.append({"ì„œë¹„ìŠ¤ëª…": service_name, "ì§€ì›ëŒ€ìƒ": "ì˜¤ë¥˜", "ì„œë¹„ìŠ¤ ë‚´ìš©": "ì˜¤ë¥˜", "í•„ìš”ì„œë¥˜": "ì˜¤ë¥˜"})
    
#     driver.quit()
#     print("ğŸ‰ ìƒì„¸ ì •ë³´ ìŠ¤í¬ë˜í•‘ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.")
#     return final_results


# def save_results(data):
#     """
#     ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ CSVì™€ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
#     """
#     if not data:
#         print("âš ï¸ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
#         return
        
#     print("\nâœ… [3ë‹¨ê³„] ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.")
    
#     # í•„ë“œ ìˆœì„œ ê³ ì •
#     fieldnames = ["ì„œë¹„ìŠ¤ëª…", "ì§€ì›ëŒ€ìƒ", "ì„œë¹„ìŠ¤ ë‚´ìš©", "í•„ìš”ì„œë¥˜"]
    
#     try:
#         with open('bokjiro_services.csv', 'w', newline='', encoding='utf-8-sig') as f:
#             writer = csv.DictWriter(f, fieldnames=fieldnames)
#             writer.writeheader()
#             for row in data:
#                 writer.writerow({key: row.get(key, "") for key in fieldnames})
#         print("ğŸ’¾ CSV íŒŒì¼ ì €ì¥ ì™„ë£Œ: bokjiro_services.csv")
#     except Exception as e:
#         print(f"âŒ CSV íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
        
#     try:
#         with open('bokjiro_services.json', 'w', encoding='utf-8') as f:
#             json.dump(data, f, ensure_ascii=False, indent=4)
#         print("ğŸ’¾ JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ: bokjiro_services.json")
#     except Exception as e:
#         print(f"âŒ JSON íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")


# # --- ë©”ì¸ ì½”ë“œ ì‹¤í–‰ ---
# if __name__ == "__main__":
    
#     # ğŸ§ª í…ŒìŠ¤íŠ¸ìš© (10ê°œë§Œ ìˆ˜ì§‘)
#     services_list = get_all_service_list(limit=10)
    
#     # ğŸš€ ì „ì²´ í¬ë¡¤ë§í•˜ë ¤ë©´ ìœ„ ì¤„ì„ ì£¼ì„ì²˜ë¦¬í•˜ê³  ì•„ë˜ ì¤„ ì‚¬ìš©
#     # services_list = get_all_service_list()
    
#     if services_list:
#         detailed_data = scrape_details_by_clicking_tabs(services_list)
#         save_results(detailed_data)
        
#     print("\nâœ¨ ëª¨ë“  í¬ë¡¤ë§ ì‘ì—…ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
# import requests
# import json
# import csv
# import time
# from selenium import webdriver
# from selenium.webdriver.chrome.service import Service
# from selenium.webdriver.common.by import By
# from selenium.webdriver.support.ui import WebDriverWait
# from selenium.webdriver.support import expected_conditions as EC
# from selenium.common.exceptions import TimeoutException
# from webdriver_manager.chrome import ChromeDriverManager

# def get_all_service_list(limit=None):
#     """
#     ë³µì§€ë¡œ APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì„œë¹„ìŠ¤ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
#     limitì´ ì§€ì •ë˜ë©´ í•´ë‹¹ ê°œìˆ˜ë§Œí¼ë§Œ ê°€ì ¸ì˜µë‹ˆë‹¤.
#     """
#     print("âœ… [1ë‹¨ê³„] ë³µì§€ ì„œë¹„ìŠ¤ ëª©ë¡ ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
#     list_url = "https://www.bokjiro.go.kr/ssis-tbu/TWAT52005M/twataa/wlfareInfo/selectWlfareInfo.do"
#     headers = {
#         'Accept': 'application/json, text/javascript, */*; q=0.01',
#         'Content-Type': 'application/json; charset=UTF-8',
#         'Referer': 'https://www.bokjiro.go.kr/ssis-tbu/twataa/wlfareInfo/moveTWAT52005M.do',
#         'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36',
#     }
#     payload_template = {
#         "dmSearchParam": {"page": "1", "pageUnit": "100", "onlineYn": "", "searchTerm": "", "tabId": "1", "orderBy": "date", "bkjrLftmCycCd": "", "daesang": "", "period": "", "age": "", "region": "", "jjim": "", "subject": "", "favoriteKeyword": "Y", "sido": "", "gungu": "", "endYn": "N"},
#         "dmScr": {"curScrId": "tbu/app/twat/twata/twataa/TWAT52005M", "befScrId": ""}
#     }
#     all_services, current_page = [], 1
#     while True:
#         if limit and len(all_services) >= limit: break
#         print(f"ğŸ“„ ëª©ë¡ {current_page}í˜ì´ì§€ë¥¼ ìš”ì²­í•©ë‹ˆë‹¤...")
#         payload_template["dmSearchParam"]["page"] = str(current_page)
#         try:
#             response = requests.post(list_url, headers=headers, json=payload_template)
#             response.raise_for_status()
#             data = response.json()
#             services_on_page = []
#             for i in range(4): services_on_page.extend(data.get(f"dsServiceList{i}", []))
#             if not services_on_page: print("âœ”ï¸ ë” ì´ìƒ ê°€ì ¸ì˜¬ ëª©ë¡ì´ ì—†ìŠµë‹ˆë‹¤."); break
#             for service in services_on_page: all_services.append({"id": service.get("WLFARE_INFO_ID"), "name": service.get("WLFARE_INFO_NM")})
#             if limit and len(all_services) >= limit: print(f"âœ”ï¸ ìš”ì²­í•˜ì‹  {limit}ê°œ ì´ìƒì˜ ëª©ë¡ì„ ìˆ˜ì§‘í•˜ì—¬ ì¤‘ë‹¨í•©ë‹ˆë‹¤."); break
#             current_page += 1
#             time.sleep(0.5)
#         except Exception as e: print(f"âŒ ëª©ë¡ ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"); break
#     if limit: all_services = all_services[:limit]
#     print(f"ğŸ‰ ì´ {len(all_services)}ê°œì˜ ì„œë¹„ìŠ¤ ëª©ë¡ì„ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤.")
#     return all_services

# def scrape_details_by_clicking_tabs(services):
#     """
#     Seleniumìœ¼ë¡œ ê° ì„œë¹„ìŠ¤ì˜ íƒ­ì„ í´ë¦­í•˜ë©° ìƒì„¸ ë‚´ìš©ì„ ìŠ¤í¬ë˜í•‘í•˜ëŠ” ìµœì¢… ì•ˆì •í™” ë²„ì „ì…ë‹ˆë‹¤.
#     """
#     print("\nâœ… [2ë‹¨ê³„] Seleniumìœ¼ë¡œ ìƒì„¸ ì •ë³´ ìŠ¤í¬ë˜í•‘ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
#     options = webdriver.ChromeOptions()
#     options.add_experimental_option('excludeSwitches', ['enable-logging'])
#     options.add_argument('--log-level=3')
#     # options.add_argument("--headless") # ì°½ ìˆ¨ê¸°ê¸°
#     options.add_argument("--no-sandbox")
#     options.add_argument("--disable-dev-shm-usage")
#     options.add_argument("--disable-gpu")
#     options.add_argument("window-size=1920x1080")
#     driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
#     final_results, total = [], len(services)
#     for i, service in enumerate(services):
#         service_id, service_name = service['id'], service['name']
#         if not service_id: continue
#         detail_url = f"https://www.bokjiro.go.kr/ssis-tbu/twataa/wlfareInfo/moveTWAT52011M.do?wlfareInfoId={service_id}"
#         print(f"({i+1}/{total}) ìŠ¤í¬ë˜í•‘ ì¤‘: {service_name[:30]}...")
#         try:
#             driver.get(detail_url)
#             try: WebDriverWait(driver, 3).until(EC.element_to_be_clickable((By.CSS_SELECTOR, "#research_pop .btn-close-pop"))).click()
#             except TimeoutException: pass
            
#             # ìŠ¤í¬ë˜í•‘í•  íƒ­ ì´ë¦„ ëª©ë¡
#             tabs_to_scrape = ["ì§€ì›ëŒ€ìƒ", "ì„œë¹„ìŠ¤ ë‚´ìš©", "í•„ìš”ì„œë¥˜"]
#             scraped_content = {"ì„œë¹„ìŠ¤ëª…": service_name}
            
#             for tab_name in tabs_to_scrape:
#                 try:
#                     # 1. íƒ­ ë²„íŠ¼ í´ë¦­
#                     tab_button = WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.XPATH, f"//a[@class='cl-text-wrapper' and contains(., '{tab_name}')]")))
#                     tab_button.click()
                    
#                     # 2. ì•ˆì •ì ì¸ ë¡œë”©ì„ ìœ„í•´ 1.5ì´ˆ ëŒ€ê¸° (ê°€ì¥ ì¤‘ìš”í•œ ë¶€ë¶„)
#                     time.sleep(1.5)
                    
#                     # 3. ì •í™•í•œ ì½˜í…ì¸  ì˜ì—­ì„ ì§€ì •í•˜ì—¬ í…ìŠ¤íŠ¸ ì¶”ì¶œ
#                     content_container = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.CSS_SELECTOR, "div.tab-content-inner")))
#                     scraped_content[tab_name] = content_container.text.strip()
#                 except Exception:
#                     # í•´ë‹¹ íƒ­ì´ ì—†ëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„
#                     scraped_content[tab_name] = "ë‚´ìš© ì—†ìŒ"
            
#             final_results.append(scraped_content)
            
#         except Exception as e:
#             print(f"  - í˜ì´ì§€ ì²˜ë¦¬ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {service_name} ({e.__class__.__name__})")
#             final_results.append({"ì„œë¹„ìŠ¤ëª…": service_name, "ì§€ì›ëŒ€ìƒ": "ì˜¤ë¥˜", "ì„œë¹„ìŠ¤ ë‚´ìš©": "ì˜¤ë¥˜", "í•„ìš”ì„œë¥˜": "ì˜¤ë¥˜"})
#     driver.quit()
#     print("ğŸ‰ ìƒì„¸ ì •ë³´ ìŠ¤í¬ë˜í•‘ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.")
#     return final_results

# def save_results(data):
#     """
#     ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ CSVì™€ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
#     """
#     if not data: print("âš ï¸ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."); return
#     print("\nâœ… [3ë‹¨ê³„] ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.")
    
#     # CSV ì €ì¥ ì‹œ í•„ë“œ(ì—´) ìˆœì„œë¥¼ ê³ ì •í•˜ê³ , ì—†ëŠ” ê°’ì€ ë¹ˆì¹¸ìœ¼ë¡œ ì²˜ë¦¬
#     fieldnames = ["ì„œë¹„ìŠ¤ëª…", "ì§€ì›ëŒ€ìƒ", "ì„œë¹„ìŠ¤ ë‚´ìš©", "í•„ìš”ì„œë¥˜"]
#     try:
#         with open('bokjiro_services.csv', 'w', newline='', encoding='utf-8-sig') as f:
#             writer = csv.DictWriter(f, fieldnames=fieldnames)
#             writer.writeheader()
#             for row in data:
#                 writer.writerow({key: row.get(key, "") for key in fieldnames})
#         print("ğŸ’¾ CSV íŒŒì¼ ì €ì¥ ì™„ë£Œ: bokjiro_services.csv")
#     except Exception as e: print(f"âŒ CSV íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
#     try:
#         with open('bokjiro_services.json', 'w', encoding='utf-8') as f: json.dump(data, f, ensure_ascii=False, indent=4)
#         print("ğŸ’¾ JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ: bokjiro_services.json")
#     except Exception as e: print(f"âŒ JSON íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")

# # --- ë©”ì¸ ì½”ë“œ ì‹¤í–‰ ---
# if __name__ == "__main__":
#     services_list = get_all_service_list(limit=10)
#     if services_list:
#         detailed_data = scrape_details_by_clicking_tabs(services_list)
#         save_results(detailed_data)
#     print("\nâœ¨ ëª¨ë“  í¬ë¡¤ë§ ì‘ì—…ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

# import requests
# import json
# import csv
# import time
# from selenium import webdriver
# from selenium.webdriver.chrome.service import Service
# from selenium.webdriver.common.by import By
# from selenium.webdriver.support.ui import WebDriverWait
# from selenium.webdriver.support import expected_conditions as EC
# from selenium.common.exceptions import TimeoutException
# from webdriver_manager.chrome import ChromeDriverManager

# def get_all_service_list(limit=None):
#     """
#     ë³µì§€ë¡œ APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì„œë¹„ìŠ¤ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
#     limitì´ ì§€ì •ë˜ë©´ í•´ë‹¹ ê°œìˆ˜ë§Œí¼ë§Œ ê°€ì ¸ì˜µë‹ˆë‹¤.
#     """
#     print("âœ… [1ë‹¨ê³„] ë³µì§€ ì„œë¹„ìŠ¤ ëª©ë¡ ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
#     list_url = "https://www.bokjiro.go.kr/ssis-tbu/TWAT52005M/twataa/wlfareInfo/selectWlfareInfo.do"
#     headers = {
#         'Accept': 'application/json, text/javascript, */*; q=0.01',
#         'Content-Type': 'application/json; charset=UTF-8',
#         'Referer': 'https://www.bokjiro.go.kr/ssis-tbu/twataa/wlfareInfo/moveTWAT52005M.do',
#         'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36',
#     }
#     payload_template = {
#         "dmSearchParam": {"page": "1", "pageUnit": "100", "onlineYn": "", "searchTerm": "", "tabId": "1", "orderBy": "date", "bkjrLftmCycCd": "", "daesang": "", "period": "", "age": "", "region": "", "jjim": "", "subject": "", "favoriteKeyword": "Y", "sido": "", "gungu": "", "endYn": "N"},
#         "dmScr": {"curScrId": "tbu/app/twat/twata/twataa/TWAT52005M", "befScrId": ""}
#     }
#     all_services, current_page = [], 1
#     while True:
#         if limit and len(all_services) >= limit: break
#         print(f"ğŸ“„ ëª©ë¡ {current_page}í˜ì´ì§€ë¥¼ ìš”ì²­í•©ë‹ˆë‹¤...")
#         payload_template["dmSearchParam"]["page"] = str(current_page)
#         try:
#             response = requests.post(list_url, headers=headers, json=payload_template)
#             response.raise_for_status()
#             data = response.json()
#             services_on_page = []
#             for i in range(4): services_on_page.extend(data.get(f"dsServiceList{i}", []))
#             if not services_on_page: print("âœ”ï¸ ë” ì´ìƒ ê°€ì ¸ì˜¬ ëª©ë¡ì´ ì—†ìŠµë‹ˆë‹¤."); break
#             for service in services_on_page: all_services.append({"id": service.get("WLFARE_INFO_ID"), "name": service.get("WLFARE_INFO_NM")})
#             if limit and len(all_services) >= limit: print(f"âœ”ï¸ ìš”ì²­í•˜ì‹  {limit}ê°œ ì´ìƒì˜ ëª©ë¡ì„ ìˆ˜ì§‘í•˜ì—¬ ì¤‘ë‹¨í•©ë‹ˆë‹¤."); break
#             current_page += 1
#             time.sleep(0.5)
#         except Exception as e: print(f"âŒ ëª©ë¡ ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"); break
#     if limit: all_services = all_services[:limit]
#     print(f"ğŸ‰ ì´ {len(all_services)}ê°œì˜ ì„œë¹„ìŠ¤ ëª©ë¡ì„ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤.")
#     return all_services

# def scrape_details_by_clicking_tabs(services):
#     """
#     ìë°”ìŠ¤í¬ë¦½íŠ¸ í´ë¦­ì„ ì‚¬ìš©í•˜ì—¬ ì•ˆì •ì„±ì„ ê·¹ëŒ€í™”í•œ ìµœì¢… ë²„ì „ì…ë‹ˆë‹¤.
#     """
#     print("\nâœ… [2ë‹¨ê³„] Seleniumìœ¼ë¡œ ìƒì„¸ ì •ë³´ ìŠ¤í¬ë˜í•‘ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
#     options = webdriver.ChromeOptions()
#     options.add_experimental_option('excludeSwitches', ['enable-logging'])
#     options.add_argument('--log-level=3')
#     # options.add_argument("--headless") # ì°½ ìˆ¨ê¸°ê¸°
#     options.add_argument("--no-sandbox")
#     options.add_argument("--disable-dev-shm-usage")
#     options.add_argument("--disable-gpu")
#     options.add_argument("window-size=1920x1080")
#     driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
#     final_results, total = [], len(services)
#     for i, service in enumerate(services):
#         service_id, service_name = service['id'], service['name']
#         if not service_id: continue
#         detail_url = f"https://www.bokjiro.go.kr/ssis-tbu/twataa/wlfareInfo/moveTWAT52011M.do?wlfareInfoId={service_id}"
#         print(f"({i+1}/{total}) ìŠ¤í¬ë˜í•‘ ì¤‘: {service_name[:30]}...")
#         try:
#             driver.get(detail_url)
#             try: WebDriverWait(driver, 3).until(EC.element_to_be_clickable((By.CSS_SELECTOR, "#research_pop .btn-close-pop"))).click()
#             except TimeoutException: pass
            
#             tabs_to_scrape = ["ì§€ì›ëŒ€ìƒ", "ì„œë¹„ìŠ¤ ë‚´ìš©", "í•„ìš”ì„œë¥˜"]
#             scraped_content = {"ì„œë¹„ìŠ¤ëª…": service_name}
            
#             for tab_name in tabs_to_scrape:
#                 try:
#                     tab_button = WebDriverWait(driver, 5).until(
#                         EC.element_to_be_clickable((
#                             By.XPATH, f"//a[@class='cl-text-wrapper' and contains(., '{tab_name}')]"
#                             ))
#                         )
#                     tab_button.click()
#                     # ì»¨í…Œì´ë„ˆ ì—¬ëŸ¬ ê°œ ì¤‘ ë§ˆì§€ë§‰ ê²ƒ ì„ íƒ
#                     containers = WebDriverWait(driver, 15). untill(
#                         EC.presence_of_all_elements_located((By.CSS_SELECTOR, "div.bokjiConts"))
#                     )    
#                     content_container = containers[-1]
                    
#                     WebDriverWait(driver, 15).untill(
#                         lambda d: content_container.text.strip()!=""
#                     )
#                     scraped_content[tab_name] = content_container.text.strip()
#                 except Exception:
#                     scraped_content[tab_name] = "ë‚´ìš© ì—†ìŒ"
            
#             final_results.append(scraped_content)
            
#         except Exception as e:
#             print(f"  - í˜ì´ì§€ ì²˜ë¦¬ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {service_name} ({e.__class__.__name__})")
#             final_results.append({"ì„œë¹„ìŠ¤ëª…": service_name, "ì§€ì›ëŒ€ìƒ": "ì˜¤ë¥˜", "ì„œë¹„ìŠ¤ ë‚´ìš©": "ì˜¤ë¥˜", "í•„ìš”ì„œë¥˜": "ì˜¤ë¥˜"})
#     driver.quit()
#     print("ğŸ‰ ìƒì„¸ ì •ë³´ ìŠ¤í¬ë˜í•‘ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.")
#     return final_results

# def save_results(data):
#     """
#     ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ CSVì™€ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
#     """
#     if not data: print("âš ï¸ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."); return
#     print("\nâœ… [3ë‹¨ê³„] ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.")
#     fieldnames = ["ì„œë¹„ìŠ¤ëª…", "ì§€ì›ëŒ€ìƒ", "ì„œë¹„ìŠ¤ ë‚´ìš©", "í•„ìš”ì„œë¥˜"]
#     try:
#         with open('bokjiro_services.csv', 'w', newline='', encoding='utf-8-sig') as f:
#             writer = csv.DictWriter(f, fieldnames=fieldnames)
#             writer.writeheader()
#             for row in data:
#                 writer.writerow({key: row.get(key, "") for key in fieldnames})
#         print("ğŸ’¾ CSV íŒŒì¼ ì €ì¥ ì™„ë£Œ: bokjiro_services.csv")
#     except Exception as e: print(f"âŒ CSV íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
#     try:
#         with open('bokjiro_services.json', 'w', encoding='utf-8') as f: json.dump(data, f, ensure_ascii=False, indent=4)
#         print("ğŸ’¾ JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ: bokjiro_services.json")
#     except Exception as e: print(f"âŒ JSON íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")

# # --- ë©”ì¸ ì½”ë“œ ì‹¤í–‰ ---
# if __name__ == "__main__":
#     services_list = get_all_service_list(limit=10) # 10ê°œë§Œ í…ŒìŠ¤íŠ¸
#     if services_list:
#         detailed_data = scrape_details_by_clicking_tabs(services_list)
#         save_results(detailed_data)
#     print("\nâœ¨ ëª¨ë“  í¬ë¡¤ë§ ì‘ì—…ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

# import requests
# import json
# import csv
# import time
# from selenium import webdriver
# from selenium.webdriver.chrome.service import Service
# from selenium.webdriver.common.by import By
# from selenium.webdriver.support.ui import WebDriverWait
# from selenium.webdriver.support import expected_conditions as EC
# from selenium.common.exceptions import TimeoutException
# from webdriver_manager.chrome import ChromeDriverManager


# def get_all_service_list(limit=None):
#     """
#     ë³µì§€ë¡œ APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì„œë¹„ìŠ¤ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
#     limitì´ ì§€ì •ë˜ë©´ í•´ë‹¹ ê°œìˆ˜ë§Œí¼ë§Œ ê°€ì ¸ì˜µë‹ˆë‹¤.
#     """
#     print("âœ… [1ë‹¨ê³„] ë³µì§€ ì„œë¹„ìŠ¤ ëª©ë¡ ìˆ˜ì§‘ ì‹œì‘")
#     list_url = "https://www.bokjiro.go.kr/ssis-tbu/TWAT52005M/twataa/wlfareInfo/selectWlfareInfo.do"
#     headers = {
#         'Accept': 'application/json, text/javascript, */*; q=0.01',
#         'Content-Type': 'application/json; charset=UTF-8',
#         'Referer': 'https://www.bokjiro.go.kr/ssis-tbu/twataa/wlfareInfo/moveTWAT52005M.do',
#         'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36',
#     }
#     payload_template = {
#         "dmSearchParam": {
#             "page": "1", "pageUnit": "100", "onlineYn": "", "searchTerm": "", "tabId": "1", "orderBy": "date",
#             "bkjrLftmCycCd": "", "daesang": "", "period": "", "age": "", "region": "", "jjim": "",
#             "subject": "", "favoriteKeyword": "Y", "sido": "", "gungu": "", "endYn": "N"
#         },
#         "dmScr": {"curScrId": "tbu/app/twat/twata/twataa/TWAT52005M", "befScrId": ""}
#     }
    
#     all_services = []
#     current_page = 1
    
#     while True:
#         if limit and len(all_services) >= limit:
#             break
            
#         print(f"ğŸ“„ ëª©ë¡ {current_page}í˜ì´ì§€ ìš”ì²­")
#         payload_template["dmSearchParam"]["page"] = str(current_page)
        
#         try:
#             response = requests.post(list_url, headers=headers, json=payload_template)
#             response.raise_for_status()
#             data = response.json()
            
#             services_on_page = []
#             for i in range(4):
#                 services_on_page.extend(data.get(f"dsServiceList{i}", []))

#             if not services_on_page:
#                 print("âœ”ï¸ ë” ì´ìƒ ê°€ì ¸ì˜¬ ëª©ë¡ ì—†ìŒ")
#                 break
            
#             for service in services_on_page:
#                 all_services.append({
#                     "id": service.get("WLFARE_INFO_ID"),
#                     "name": service.get("WLFARE_INFO_NM")
#                 })
            
#             if limit and len(all_services) >= limit:
#                 print(f"âœ”ï¸ {limit}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")
#                 break
            
#             current_page += 1
#             time.sleep(0.5)
            
#         except Exception as e:
#             print(f"âŒ ëª©ë¡ ìš”ì²­ ì˜¤ë¥˜: {e}")
#             break
    
#     if limit:
#         all_services = all_services[:limit]

#     print(f"ğŸ‰ ì´ {len(all_services)}ê°œ ì„œë¹„ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ")
#     return all_services


# def scrape_details_by_clicking_tabs(services):
#     """
#     Seleniumìœ¼ë¡œ ê° ì„œë¹„ìŠ¤ì˜ 'ì§€ì›ëŒ€ìƒ', 'ì„œë¹„ìŠ¤ ë‚´ìš©' íƒ­ì„ ìŠ¤í¬ë˜í•‘í•©ë‹ˆë‹¤.
#     """
#     print("\nâœ… [2ë‹¨ê³„] ìƒì„¸ ì •ë³´ ìŠ¤í¬ë˜í•‘ ì‹œì‘")
    
#     options = webdriver.ChromeOptions()
#     options.add_experimental_option('excludeSwitches', ['enable-logging'])
#     options.add_argument('--log-level=3')
#     options.add_argument("--headless")  # ğŸ‘‰ ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰
#     options.add_argument("--no-sandbox")
#     options.add_argument("--disable-dev-shm-usage")
#     options.add_argument("--disable-gpu")
#     options.add_argument("window-size=1920x1080")
    
#     driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
    
#     final_results = []
#     total = len(services)
    
#     # íƒ­ë³„ ì„ íƒì
#     tab_selectors = {
#         "ì§€ì›ëŒ€ìƒ": "div.bokjiServiceView div.bokjiConts",
#         "ì„œë¹„ìŠ¤ ë‚´ìš©": "div.bokjiConts"
#     }
    
#     for i, service in enumerate(services):
#         service_id, service_name = service['id'], service['name']
#         if not service_id: 
#             continue
            
#         detail_url = (
#             f"https://www.bokjiro.go.kr/ssis-tbu/twataa/wlfareInfo/"
#             f"moveTWAT52011M.do?wlfareInfoId={service_id}&wlfareInfoReldBztpCd=01"
#         )
#         print(f"({i+1}/{total}) {service_name[:30]} ìŠ¤í¬ë˜í•‘ ì¤‘...")
        
#         try:
#             driver.get(detail_url)
            
#             # íŒì—… ë‹«ê¸° (ìˆì„ ê²½ìš°)
#             try:
#                 popup_close_button = WebDriverWait(driver, 3).until(
#                     EC.element_to_be_clickable((By.CSS_SELECTOR, "#research_pop .btn-close-pop"))
#                 )
#                 popup_close_button.click()
#             except TimeoutException:
#                 pass
            
#             # ì‹¤ì œ ìˆ˜ì§‘í•  íƒ­ë“¤
#             tabs_to_scrape = ["ì§€ì›ëŒ€ìƒ", "ì„œë¹„ìŠ¤ ë‚´ìš©"]
#             scraped_content = {"ì„œë¹„ìŠ¤ëª…": service_name}
            
#             for tab_name in tabs_to_scrape:
#                 try:
#                     # íƒ­ ë²„íŠ¼ í´ë¦­ (title ì†ì„± í™œìš©)
#                     tab_button = WebDriverWait(driver, 10).until(
#                         EC.element_to_be_clickable((By.XPATH, f"//a[contains(@title, '{tab_name}')]"))
#                     )
#                     tab_button.click()

#                     selector = tab_selectors.get(tab_name, "div.bokjiConts")

#                     # ë³¸ë¬¸ ì»¨í…Œì´ë„ˆ ëŒ€ê¸°
#                     content_container = WebDriverWait(driver, 15).until(
#                         EC.presence_of_element_located((By.CSS_SELECTOR, selector))
#                     )

#                     # í…ìŠ¤íŠ¸ ë¡œë”© ì™„ë£Œê¹Œì§€ ëŒ€ê¸°
#                     WebDriverWait(driver, 15).until(
#                         lambda d: content_container.text.strip() != ""
#                     )

#                     scraped_content[tab_name] = content_container.text.strip()

#                 except Exception as e:
#                     scraped_content[tab_name] = f"ë‚´ìš©ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ ({type(e).__name__})"
            
#             final_results.append(scraped_content)
            
#         except Exception as e:
#             print(f"  - í˜ì´ì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {service_name} ({e.__class__.__name__})")
#             final_results.append({"ì„œë¹„ìŠ¤ëª…": service_name, "ì§€ì›ëŒ€ìƒ": "ì˜¤ë¥˜", "ì„œë¹„ìŠ¤ ë‚´ìš©": "ì˜¤ë¥˜"})
    
#     driver.quit()
#     print("ğŸ‰ ìƒì„¸ ì •ë³´ ìŠ¤í¬ë˜í•‘ ì™„ë£Œ")
#     return final_results


# def save_results(data):
#     """
#     ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ CSVì™€ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
#     """
#     if not data:
#         print("âš ï¸ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
#         return
        
#     print("\nâœ… [3ë‹¨ê³„] íŒŒì¼ ì €ì¥ ì‹œì‘")
    
#     # í•„ë“œ ìˆœì„œ ê³ ì •
#     fieldnames = ["ì„œë¹„ìŠ¤ëª…", "ì§€ì›ëŒ€ìƒ", "ì„œë¹„ìŠ¤ ë‚´ìš©"]
    
#     try:
#         with open('bokjiro_services.csv', 'w', newline='', encoding='utf-8-sig') as f:
#             writer = csv.DictWriter(f, fieldnames=fieldnames)
#             writer.writeheader()
#             for row in data:
#                 writer.writerow({key: row.get(key, "") for key in fieldnames})
#         print("ğŸ’¾ CSV ì €ì¥ ì™„ë£Œ: bokjiro_services.csv")
#     except Exception as e:
#         print(f"âŒ CSV ì €ì¥ ì˜¤ë¥˜: {e}")
        
#     try:
#         with open('bokjiro_services.json', 'w', encoding='utf-8') as f:
#             json.dump(data, f, ensure_ascii=False, indent=4)
#         print("ğŸ’¾ JSON ì €ì¥ ì™„ë£Œ: bokjiro_services.json")
#     except Exception as e:
#         print(f"âŒ JSON ì €ì¥ ì˜¤ë¥˜: {e}")


# # --- ë©”ì¸ ì‹¤í–‰ ---
# if __name__ == "__main__":
    
#     # ğŸ§ª í…ŒìŠ¤íŠ¸ìš© (10ê°œë§Œ ìˆ˜ì§‘)
#     services_list = get_all_service_list(limit=10)
    
#     # ğŸš€ ì „ì²´ í¬ë¡¤ë§ í•˜ë ¤ë©´ ìœ„ ì¤„ ì£¼ì„ ì²˜ë¦¬í•˜ê³  ì•„ë˜ ì‚¬ìš©
#     # services_list = get_all_service_list()
    
#     if services_list:
#         detailed_data = scrape_details_by_clicking_tabs(services_list)
#         save_results(detailed_data)
        
#     print("\nâœ¨ ëª¨ë“  ì‘ì—… ì¢…ë£Œ")

import requests
import json
import csv
import time
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException
from webdriver_manager.chrome import ChromeDriverManager


def get_all_service_list(limit=None):
    """
    ë³µì§€ë¡œ APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì„œë¹„ìŠ¤ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    limitì´ ì§€ì •ë˜ë©´ í•´ë‹¹ ê°œìˆ˜ë§Œí¼ë§Œ ê°€ì ¸ì˜¤ê³  ì¤‘ë‹¨í•©ë‹ˆë‹¤.
    """
    print("âœ… [1ë‹¨ê³„] ë³µì§€ ì„œë¹„ìŠ¤ ëª©ë¡ ìˆ˜ì§‘ ì‹œì‘")
    list_url = "https://www.bokjiro.go.kr/ssis-tbu/TWAT52005M/twataa/wlfareInfo/selectWlfareInfo.do"
    headers = {
        "Accept": "application/json, text/javascript, */*; q=0.01",
        "Content-Type": "application/json; charset=UTF-8",
        "Referer": "https://www.bokjiro.go.kr/ssis-tbu/twataa/wlfareInfo/moveTWAT52005M.do",
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36",
    }
    payload_template = {
        "dmSearchParam": {
            "page": "1",
            "pageUnit": "100",
            "onlineYn": "",
            "searchTerm": "",
            "tabId": "1",
            "orderBy": "date",
            "bkjrLftmCycCd": "",
            "daesang": "",
            "period": "",
            "age": "",
            "region": "",
            "jjim": "",
            "subject": "",
            "favoriteKeyword": "Y",
            "sido": "",
            "gungu": "",
            "endYn": "N",
        },
        "dmScr": {
            "curScrId": "tbu/app/twat/twata/twataa/TWAT52005M",
            "befScrId": "",
        },
    }

    all_services = []
    current_page = 1

    while True:
        if limit and len(all_services) >= limit:
            break

        print(f"ğŸ“„ ëª©ë¡ {current_page}í˜ì´ì§€ ìš”ì²­ ì¤‘...")
        payload_template["dmSearchParam"]["page"] = str(current_page)

        try:
            response = requests.post(list_url, headers=headers, json=payload_template)
            response.raise_for_status()
            data = response.json()

            services_on_page = []
            for i in range(4):
                services_on_page.extend(data.get(f"dsServiceList{i}", []))

            if not services_on_page:
                print("âœ”ï¸ ë” ì´ìƒ ê°€ì ¸ì˜¬ ëª©ë¡ ì—†ìŒ")
                break

            for service in services_on_page:
                all_services.append(
                    {
                        "id": service.get("WLFARE_INFO_ID"),
                        "name": service.get("WLFARE_INFO_NM"),
                    }
                )

            if limit and len(all_services) >= limit:
                print(f"âœ”ï¸ {limit}ê°œ ìˆ˜ì§‘ ì™„ë£Œ, ì¤‘ë‹¨")
                break

            current_page += 1
            time.sleep(0.5)

        except Exception as e:
            print(f"âŒ ëª©ë¡ ìš”ì²­ ì˜¤ë¥˜: {e}")
            break

    if limit:
        all_services = all_services[:limit]

    print(f"ğŸ‰ ì´ {len(all_services)}ê°œ ì„œë¹„ìŠ¤ ëª©ë¡ ìˆ˜ì§‘")
    return all_services


def scrape_details_by_clicking_tabs(services):
    """
    Seleniumìœ¼ë¡œ ê° ì„œë¹„ìŠ¤ í˜ì´ì§€ì—ì„œ 'ì§€ì›ëŒ€ìƒ', 'ì„œë¹„ìŠ¤ ë‚´ìš©' íƒ­(ë˜ëŠ” ë³¸ë¬¸)ì„ ìŠ¤í¬ë˜í•‘
    """
    print("\nâœ… [2ë‹¨ê³„] ìƒì„¸ ì •ë³´ ìŠ¤í¬ë˜í•‘ ì‹œì‘")

    options = webdriver.ChromeOptions()
    options.add_experimental_option("excludeSwitches", ["enable-logging"])
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-gpu")
    options.add_argument("window-size=1920x1080")
    # options.add_argument("--headless")  # ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰í•˜ë ¤ë©´ ì£¼ì„ í•´ì œ

    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)

    final_results = []
    total = len(services)

    # íƒ­ ë³¸ë¬¸ CSS ì„ íƒì ì •ì˜
    tab_selectors = {
        "ì§€ì›ëŒ€ìƒ": "div.bokjiServiceView div.bokjiConts",
        "ì„œë¹„ìŠ¤ ë‚´ìš©": "div.bokjiConts",
    }

    for i, service in enumerate(services):
        service_id, service_name = service["id"], service["name"]
        if not service_id:
            continue

        detail_url = f"https://www.bokjiro.go.kr/ssis-tbu/twataa/wlfareInfo/moveTWAT52011M.do?wlfareInfoId={service_id}"
        print(f"({i+1}/{total}) {service_name[:30]}...")

        scraped_content = {"ì„œë¹„ìŠ¤ëª…": service_name}

        try:
            driver.get(detail_url)

            # íŒì—… ë‹«ê¸° ì‹œë„
            try:
                popup_close_button = WebDriverWait(driver, 3).until(
                    EC.element_to_be_clickable((By.CSS_SELECTOR, "#research_pop .btn-close-pop"))
                )
                popup_close_button.click()
            except TimeoutException:
                pass

            # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” íƒ­ë§Œ ì²˜ë¦¬
            for tab_name in ["ì§€ì›ëŒ€ìƒ", "ì„œë¹„ìŠ¤ ë‚´ìš©"]:
                try:
                    # 1ï¸âƒ£ íƒ­ ë²„íŠ¼ í™•ì¸
                    tab_buttons = driver.find_elements(By.XPATH, f"//a[contains(@title, '{tab_name}')]")

                    if tab_buttons:
                        tab_buttons[0].click()
                        selector = tab_selectors.get(tab_name, "div.bokjiConts")
                    else:
                        # íƒ­ì´ ì—†ìœ¼ë©´ ë³¸ë¬¸ ì»¨í…Œì´ë„ˆ ë°”ë¡œ ì‚¬ìš©
                        selector = "div.bokjiConts"

                    # 2ï¸âƒ£ ë³¸ë¬¸ ì»¨í…Œì´ë„ˆ ëŒ€ê¸°
                    content_container = WebDriverWait(driver, 8).until(
                        EC.presence_of_element_located((By.CSS_SELECTOR, selector))
                    )

                    WebDriverWait(driver, 8).until(
                        lambda d: content_container.text.strip() != ""
                    )

                    scraped_content[tab_name] = content_container.text.strip()

                except Exception as e:
                    scraped_content[tab_name] = f"ë‚´ìš©ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ ({type(e).__name__})"

            final_results.append(scraped_content)

        except Exception as e:
            print(f"  - í˜ì´ì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {service_name} ({e})")
            final_results.append(
                {"ì„œë¹„ìŠ¤ëª…": service_name, "ì§€ì›ëŒ€ìƒ": "ì˜¤ë¥˜", "ì„œë¹„ìŠ¤ ë‚´ìš©": "ì˜¤ë¥˜"}
            )

    driver.quit()
    print("ğŸ‰ ìƒì„¸ ì •ë³´ ìŠ¤í¬ë˜í•‘ ì™„ë£Œ")
    return final_results


def save_results(data):
    """
    CSVì™€ JSON íŒŒì¼ë¡œ ì €ì¥
    """
    if not data:
        print("âš ï¸ ì €ì¥í•  ë°ì´í„° ì—†ìŒ")
        return

    print("\nâœ… [3ë‹¨ê³„] íŒŒì¼ ì €ì¥ ì‹œì‘")

    try:
        with open("bokjiro_services.csv", "w", newline="", encoding="utf-8-sig") as f:
            fieldnames = list(data[0].keys())
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(data)
        print("ğŸ’¾ CSV ì €ì¥ ì™„ë£Œ: bokjiro_services.csv")
    except Exception as e:
        print(f"âŒ CSV ì €ì¥ ì˜¤ë¥˜: {e}")

    try:
        with open("bokjiro_services.json", "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=4)
        print("ğŸ’¾ JSON ì €ì¥ ì™„ë£Œ: bokjiro_services.json")
    except Exception as e:
        print(f"âŒ JSON ì €ì¥ ì˜¤ë¥˜: {e}")


# --- ë©”ì¸ ì‹¤í–‰ ---
if __name__ == "__main__":
    services_list = get_all_service_list(limit=10)  # í…ŒìŠ¤íŠ¸ ì‹œ limit ì‚¬ìš©
    if services_list:
        detailed_data = scrape_details_by_clicking_tabs(services_list)
        save_results(detailed_data)

    print("\nâœ¨ ëª¨ë“  í¬ë¡¤ë§ ì‘ì—… ì¢…ë£Œ")

