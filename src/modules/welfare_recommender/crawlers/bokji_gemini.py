import requests
import json
import csv
import time
import datetime  # ë‚ ì§œì™€ ì‹œê°„ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ì¶”ê°€
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException
from webdriver_manager.chrome import ChromeDriverManager

def get_all_service_list(limit=None):
    """
    ë³µì§€ë¡œ APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì„œë¹„ìŠ¤ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    limitì´ ì§€ì •ë˜ë©´ í•´ë‹¹ ê°œìˆ˜ë§Œí¼ë§Œ ê°€ì ¸ì˜µë‹ˆë‹¤.
    """
    print("âœ… [1ë‹¨ê³„] ë³µì§€ ì„œë¹„ìŠ¤ ëª©ë¡ ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    list_url = "https://www.bokjiro.go.kr/ssis-tbu/TWAT52005M/twataa/wlfareInfo/selectWlfareInfo.do"
    headers = {
        'Accept': 'application/json, text/javascript, */*; q=0.01',
        'Content-Type': 'application/json; charset=UTF-8',
        'Referer': 'https://www.bokjiro.go.kr/ssis-tbu/twataa/wlfareInfo/moveTWAT52005M.do',
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36',
    }
    payload_template = {
        "dmSearchParam": {"page": "1", "pageUnit": "100", "onlineYn": "", "searchTerm": "", "tabId": "1", "orderBy": "date", "bkjrLftmCycCd": "", "daesang": "", "period": "", "age": "", "region": "", "jjim": "", "subject": "", "favoriteKeyword": "Y", "sido": "", "gungu": "", "endYn": "N"},
        "dmScr": {"curScrId": "tbu/app/twat/twata/twataa/TWAT52005M", "befScrId": ""}
    }
    all_services, current_page = [], 1
    while True:
        if limit and len(all_services) >= limit: break
        print(f"ğŸ“„ ëª©ë¡ {current_page}í˜ì´ì§€ë¥¼ ìš”ì²­í•©ë‹ˆë‹¤...")
        payload_template["dmSearchParam"]["page"] = str(current_page)
        try:
            response = requests.post(list_url, headers=headers, json=payload_template)
            response.raise_for_status()
            data = response.json()
            services_on_page = []
            for i in range(4): services_on_page.extend(data.get(f"dsServiceList{i}", []))
            if not services_on_page: print("âœ”ï¸ ë” ì´ìƒ ê°€ì ¸ì˜¬ ëª©ë¡ì´ ì—†ìŠµë‹ˆë‹¤."); break
            for service in services_on_page: all_services.append({"id": service.get("WLFARE_INFO_ID"), "name": service.get("WLFARE_INFO_NM")})
            if limit and len(all_services) >= limit: print(f"âœ”ï¸ ìš”ì²­í•˜ì‹  {limit}ê°œ ì´ìƒì˜ ëª©ë¡ì„ ìˆ˜ì§‘í•˜ì—¬ ì¤‘ë‹¨í•©ë‹ˆë‹¤."); break
            current_page += 1
            time.sleep(0.5)
        except Exception as e: print(f"âŒ ëª©ë¡ ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"); break
    if limit: all_services = all_services[:limit]
    print(f"ğŸ‰ ì´ {len(all_services)}ê°œì˜ ì„œë¹„ìŠ¤ ëª©ë¡ì„ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤.")
    return all_services

def scrape_details_by_clicking_tabs(services):
    """
    ìë°”ìŠ¤í¬ë¦½íŠ¸ í´ë¦­ê³¼ ì•ˆì •ì ì¸ ëŒ€ê¸° ë°©ì‹ì„ ì‚¬ìš©í•˜ì—¬ ìƒì„¸ ë‚´ìš©ì„ ìŠ¤í¬ë˜í•‘í•©ë‹ˆë‹¤.
    """
    print("\nâœ… [2ë‹¨ê³„] Seleniumìœ¼ë¡œ ìƒì„¸ ì •ë³´ ìŠ¤í¬ë˜í•‘ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    options = webdriver.ChromeOptions()
    options.add_experimental_option('excludeSwitches', ['enable-logging'])
    options.add_argument('--log-level=3')
    # options.add_argument("--headless") # ì°½ì„ ìˆ¨ê¸°ë ¤ë©´ ì´ ì¤„ì˜ ì£¼ì„ì„ í•´ì œí•˜ì„¸ìš”.
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-gpu")
    options.add_argument("window-size=1920x1080")
    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
    final_results, total = [], len(services)
    for i, service in enumerate(services):
        service_id, service_name = service['id'], service['name']
        if not service_id: continue
        detail_url = f"https://www.bokjiro.go.kr/ssis-tbu/twataa/wlfareInfo/moveTWAT52011M.do?wlfareInfoId={service_id}"
        print(f"({i+1}/{total}) ìŠ¤í¬ë˜í•‘ ì¤‘: {service_name[:30]}...")
        try:
            driver.get(detail_url)
            try: WebDriverWait(driver, 3).until(EC.element_to_be_clickable((By.CSS_SELECTOR, "#research_pop .btn-close-pop"))).click()
            except TimeoutException: pass
            
            tabs_to_scrape = ["ì§€ì›ëŒ€ìƒ", "ì„œë¹„ìŠ¤ ë‚´ìš©", "í•„ìš”ì„œë¥˜"]
            scraped_content = {"ì„œë¹„ìŠ¤ëª…": service_name}
            
            for tab_name in tabs_to_scrape:
                try:
                    tab_button = WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.XPATH, f"//a[@class='cl-text-wrapper' and contains(., '{tab_name}')]")))
                    driver.execute_script("arguments[0].click();", tab_button)
                    time.sleep(1.5)
                    content_container = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.CSS_SELECTOR, "div.tab-content-inner")))
                    scraped_content[tab_name] = content_container.text.strip()
                except Exception:
                    scraped_content[tab_name] = "ë‚´ìš© ì—†ìŒ"
            
            final_results.append(scraped_content)
            
        except Exception as e:
            print(f"  - í˜ì´ì§€ ì²˜ë¦¬ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {service_name} ({e.__class__.__name__})")
            final_results.append({"ì„œë¹„ìŠ¤ëª…": service_name, "ì§€ì›ëŒ€ìƒ": "ì˜¤ë¥˜", "ì„œë¹„ìŠ¤ ë‚´ìš©": "ì˜¤ë¥˜", "í•„ìš”ì„œë¥˜": "ì˜¤ë¥˜"})
    driver.quit()
    print("ğŸ‰ ìƒì„¸ ì •ë³´ ìŠ¤í¬ë˜í•‘ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.")
    return final_results

def save_results(data, timestamp):
    """
    ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ CSVì™€ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    íŒŒì¼ëª…ì— íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ì¶”ê°€í•˜ì—¬ ì‚¬ë³¸ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    """
    if not data: 
        print("âš ï¸ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
        
    print("\nâœ… [3ë‹¨ê³„] ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.")
    
    # --- âœ¨ ìˆ˜ì •ëœ ë¶€ë¶„ ì‹œì‘ âœ¨ ---
    base_filename = "bokjiro_services"
    csv_filename = f"{base_filename}(ì‚¬ë³¸_{timestamp}).csv"
    json_filename = f"{base_filename}(ì‚¬ë³¸_{timestamp}).json"
    # --- âœ¨ ìˆ˜ì •ëœ ë¶€ë¶„ ë âœ¨ ---
    
    fieldnames = ["ì„œë¹„ìŠ¤ëª…", "ì§€ì›ëŒ€ìƒ", "ì„œë¹„ìŠ¤ ë‚´ìš©", "í•„ìš”ì„œë¥˜"]
    try:
        with open(csv_filename, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            for row in data:
                writer.writerow({key: row.get(key, "") for key in fieldnames})
        print(f"ğŸ’¾ CSV íŒŒì¼ ì €ì¥ ì™„ë£Œ: {csv_filename}")
    except Exception as e: 
        print(f"âŒ CSV íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
    try:
        with open(json_filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=4)
        print(f"ğŸ’¾ JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ: {json_filename}")
    except Exception as e: 
        print(f"âŒ JSON íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")

# --- ë©”ì¸ ì½”ë“œ ì‹¤í–‰ ---
if __name__ == "__main__":
    
    # ğŸ§ª í…ŒìŠ¤íŠ¸: 10ê°œë§Œ ê°€ì ¸ì˜¤ë ¤ë©´ ì•„ë˜ ì¤„ì„ ì‚¬ìš©í•˜ì„¸ìš”.
    services_list = get_all_service_list(limit=10)
    
    # ğŸš€ ì „ì²´ ì‹¤í–‰: ëª¨ë“  ëª©ë¡ì„ ê°€ì ¸ì˜¤ë ¤ë©´ ìœ„ ì¤„ì„ ì£¼ì„ ì²˜ë¦¬(#)í•˜ê³  ì•„ë˜ ì¤„ì˜ ì£¼ì„ì„ í•´ì œí•˜ì„¸ìš”.
    # services_list = get_all_service_list()
    
    if services_list:
        detailed_data = scrape_details_by_clicking_tabs(services_list)
        
        # --- âœ¨ ìˆ˜ì •ëœ ë¶€ë¶„ ì‹œì‘ âœ¨ ---
        # íŒŒì¼ëª…ì— ì‚¬ìš©í•  í˜„ì¬ ì‹œê°„ ìƒì„± (ì˜ˆ: 20250920_2203)
        now = datetime.datetime.now()
        timestamp_str = now.strftime("%Y%m%d_%H%M")
        
        # save_results í•¨ìˆ˜ì— timestamp ì „ë‹¬
        save_results(detailed_data, timestamp_str)
        # --- âœ¨ ìˆ˜ì •ëœ ë¶€ë¶„ ë âœ¨ ---
        
    print("\nâœ¨ ëª¨ë“  í¬ë¡¤ë§ ì‘ì—…ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")