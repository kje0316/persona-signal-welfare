{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63f1198b",
   "metadata": {},
   "source": [
    "# 크롤링작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6162d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas requests lxml tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38eaa6db",
   "metadata": {},
   "source": [
    "## 중앙부처 - 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7c9021",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import ssl\n",
    "import time\n",
    "import os\n",
    "from requests.adapters import HTTPAdapter\n",
    "\n",
    "# ==========================\n",
    "# 사용자 입력\n",
    "# ==========================\n",
    "API_KEY = \"0f561bd1f21a64f960fff4cf634d3afeb996d252a52dae3c7fea3c70c2c9ba09\"   # ← 반드시 본인 API Key로 교체\n",
    "MASTER_CSV = \"중앙부처_복지서비스.csv\"     # 전체 서비스ID 목록\n",
    "PROCESSED_CSV = \"중앙부처_batch4.csv\"    # 이미 처리된 결과 CSV\n",
    "SERVICE_ID_COLUMN = \"서비스ID\"\n",
    "BASE_URL = \"https://apis.data.go.kr/B554287/NationalWelfareInformationsV001/NationalWelfaredetailedV001\"\n",
    "\n",
    "# ==========================\n",
    "# TLS 강제\n",
    "# ==========================\n",
    "class TLSAdapter(HTTPAdapter):\n",
    "    def init_poolmanager(self, *args, **kwargs):\n",
    "        ctx = ssl.create_default_context(ssl.Purpose.SERVER_AUTH)\n",
    "        ctx.minimum_version = ssl.TLSVersion.TLSv1_2\n",
    "        kwargs['ssl_context'] = ctx\n",
    "        return super().init_poolmanager(*args, **kwargs)\n",
    "\n",
    "session = requests.Session()\n",
    "session.mount(\"https://\", TLSAdapter())\n",
    "\n",
    "# ==========================\n",
    "# XML 파싱\n",
    "# ==========================\n",
    "def parse_service_detail(xml_text):\n",
    "    try:\n",
    "        root = ET.fromstring(xml_text)\n",
    "        node = root if root.tag == \"wantedDtl\" else root.find(\".//wantedDtl\")\n",
    "        if node is None:\n",
    "            return None\n",
    "        row = {\n",
    "            \"서비스ID\": node.findtext(\"servId\", \"\"),\n",
    "            \"서비스명\": node.findtext(\"servNm\", \"\"),\n",
    "            \"소관부처\": node.findtext(\"jurMnofNm\", \"\"),\n",
    "            \"서비스개요\": node.findtext(\"wlfareInfoOutlCn\", \"\"),\n",
    "            \"지원대상상세\": node.findtext(\"tgtrDtlCn\", \"\").strip(),\n",
    "            \"선정기준\": node.findtext(\"slctCritCn\", \"\").strip(),\n",
    "            \"지원내용\": node.findtext(\"alwServCn\", \"\").strip(),\n",
    "            \"지원주기\": node.findtext(\"sprtCycNm\", \"\"),\n",
    "            \"지급방식\": node.findtext(\"srvPvsnNm\", \"\"),\n",
    "        }\n",
    "        return row\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# ==========================\n",
    "# API 호출\n",
    "# ==========================\n",
    "def fetch_service_detail(sid):\n",
    "    params = {\"serviceKey\": API_KEY, \"servId\": sid}\n",
    "    try:\n",
    "        resp = session.get(BASE_URL, params=params, timeout=30)\n",
    "        if resp.status_code == 200:\n",
    "            return resp.text\n",
    "        else:\n",
    "            print(f\"❌ 요청 실패: {sid}, 코드 {resp.status_code}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ 요청 오류: {sid}, {e}\")\n",
    "        return None\n",
    "\n",
    "# ==========================\n",
    "# 실행 루프\n",
    "# ==========================\n",
    "def run_batch(service_ids, batch_num=1, batch_size=100):\n",
    "    rows, fail_ids = [], []\n",
    "    last_id = None\n",
    "\n",
    "    for idx, sid in enumerate(service_ids, start=1):\n",
    "        print(f\"[{idx}/{len(service_ids)}] 요청: {sid}\")\n",
    "        xml_text = fetch_service_detail(sid)\n",
    "\n",
    "        if not xml_text:\n",
    "            fail_ids.append(sid)\n",
    "            continue\n",
    "\n",
    "        data = parse_service_detail(xml_text)\n",
    "        if data:\n",
    "            rows.append(data)\n",
    "            last_id = sid\n",
    "        else:\n",
    "            fail_ids.append(sid)\n",
    "\n",
    "        time.sleep(0.5)  # API 부하 방지\n",
    "\n",
    "        # 100개 단위 저장\n",
    "        if idx % batch_size == 0:\n",
    "            file_name = f\"중앙부처_batch{batch_num}.csv\"\n",
    "            pd.DataFrame(rows).to_csv(file_name, index=False, encoding=\"utf-8-sig\")\n",
    "            print(f\"💾 Batch {batch_num} 저장 완료 ({len(rows)}개)\")\n",
    "            rows = []\n",
    "            batch_num += 1\n",
    "\n",
    "    # 남은 데이터 저장\n",
    "    if rows:\n",
    "        file_name = f\"중앙부처_batch{batch_num}.csv\"\n",
    "        pd.DataFrame(rows).to_csv(file_name, index=False, encoding=\"utf-8-sig\")\n",
    "        print(f\"💾 Batch {batch_num} 저장 완료 ({len(rows)}개)\")\n",
    "\n",
    "    # 실패 ID 저장\n",
    "    if fail_ids:\n",
    "        fail_file = f\"중앙부처_batch{batch_num}_실패.csv\"\n",
    "        pd.DataFrame(fail_ids, columns=[\"실패ID\"]).to_csv(fail_file, index=False, encoding=\"utf-8-sig\")\n",
    "        print(f\"⚠️ 실패한 ID {len(fail_ids)}건 저장됨 → {fail_file}\")\n",
    "\n",
    "    print(f\"✅ 마지막 처리된 서비스ID: {last_id}\")\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# 시작 index 계산\n",
    "# ==========================\n",
    "def get_remaining_ids(master_csv, processed_csv):\n",
    "    df_master = pd.read_csv(master_csv)\n",
    "    df_processed = pd.read_csv(processed_csv)\n",
    "\n",
    "    all_ids = df_master[SERVICE_ID_COLUMN].dropna().astype(str).tolist()\n",
    "    done_ids = df_processed[SERVICE_ID_COLUMN].dropna().astype(str).tolist()\n",
    "\n",
    "    remaining = [sid for sid in all_ids if sid not in done_ids]\n",
    "    print(f\"📊 전체 {len(all_ids)}개 중 {len(done_ids)}개 완료, {len(remaining)}개 남음\")\n",
    "    return remaining\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# 실행\n",
    "# ==========================\n",
    "if __name__ == \"__main__\":\n",
    "    remaining_ids = get_remaining_ids(MASTER_CSV, PROCESSED_CSV)\n",
    "\n",
    "    if remaining_ids:\n",
    "        run_batch(remaining_ids, batch_num=3, batch_size=100)  \n",
    "        # 👉 batch_num=3부터 시작 (1,2는 이미 완료했으니까)\n",
    "    else:\n",
    "        print(\"🎉 모든 서비스ID 크롤링 완료됨\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd40a29",
   "metadata": {},
   "source": [
    "중앙부처 실패 id 합본"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e730372f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# --- 설정 ---\n",
    "\n",
    "# 1. 찾을 실패 파일들의 패턴입니다. \n",
    "#    이 패턴에 맞는 모든 파일을 찾아냅니다. (예: 중앙부처_batch4_실패.csv, 중앙부처_재시도_재실패.csv 등)\n",
    "FILE_PATTERN = \"*_실패.csv\"\n",
    "\n",
    "# 2. 최종적으로 저장될 통합 파일의 이름입니다.\n",
    "OUTPUT_FILENAME = \"통합_실패_ID_목록.csv\"\n",
    "\n",
    "# 3. 통합 후 사용할 최종 서비스 ID 컬럼 이름입니다.\n",
    "FINAL_ID_COLUMN_NAME = \"서비스ID\"\n",
    "\n",
    "# --- 코드 실행 ---\n",
    "\n",
    "def merge_failure_files():\n",
    "    \"\"\"\n",
    "    지정된 패턴과 일치하는 모든 실패 CSV 파일을 찾아,\n",
    "    하나의 통합된 파일로 병합하고 중복을 제거합니다.\n",
    "    \"\"\"\n",
    "    # 패턴에 맞는 파일 목록을 찾습니다.\n",
    "    failure_files = glob.glob(FILE_PATTERN)\n",
    "\n",
    "    if not failure_files:\n",
    "        print(f\"❌ 오류: '{FILE_PATTERN}' 패턴에 맞는 실패 파일을 찾을 수 없습니다.\")\n",
    "        print(\"스크립트와 실패 파일들이 같은 폴더에 있는지 확인해주세요.\")\n",
    "        return\n",
    "\n",
    "    print(f\"📁 총 {len(failure_files)}개의 실패 파일을 찾았습니다:\")\n",
    "    for f in failure_files:\n",
    "        print(f\"  - {f}\")\n",
    "\n",
    "    df_list = []\n",
    "    # 각 파일을 읽어 데이터프레임 리스트에 추가합니다.\n",
    "    for file in failure_files:\n",
    "        try:\n",
    "            df = pd.read_csv(file)\n",
    "            # 컬럼 이름이 통일되도록 처리\n",
    "            # 예: '실패ID', '재실패ID' -> '서비스ID'\n",
    "            if '실패ID' in df.columns:\n",
    "                df.rename(columns={'실패ID': FINAL_ID_COLUMN_NAME}, inplace=True)\n",
    "            elif '재실패ID' in df.columns:\n",
    "                df.rename(columns={'재실패ID': FINAL_ID_COLUMN_NAME}, inplace=True)\n",
    "            \n",
    "            df_list.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ 경고: '{file}' 파일을 읽는 중 오류 발생. 건너뜁니다. ({e})\")\n",
    "\n",
    "    if not df_list:\n",
    "        print(\"\\n❌ 오류: 파일을 읽어오지 못했습니다.\")\n",
    "        return\n",
    "\n",
    "    # 모든 데이터프레임을 하나로 합칩니다.\n",
    "    print(\"\\n파일 병합 및 중복 제거를 시작합니다...\")\n",
    "    combined_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "    # 최종 ID 컬럼이 있는지 확인하고 중복을 제거합니다.\n",
    "    if FINAL_ID_COLUMN_NAME in combined_df.columns:\n",
    "        initial_rows = len(combined_df)\n",
    "        # 중복된 ID를 제거하고, 최종적으로 유니크한 ID 목록만 남깁니다.\n",
    "        combined_df.drop_duplicates(subset=[FINAL_ID_COLUMN_NAME], keep='first', inplace=True)\n",
    "        final_rows = len(combined_df)\n",
    "        print(f\"  - 총 {initial_rows}개의 ID를 {final_rows}개의 고유 ID로 정리했습니다.\")\n",
    "    else:\n",
    "        print(f\"⚠️ 경고: '{FINAL_ID_COLUMN_NAME}' 컬럼을 찾을 수 없어 중복 제거를 건너뜁니다.\")\n",
    "        \n",
    "    # 최종 결과를 CSV 파일로 저장합니다.\n",
    "    try:\n",
    "        combined_df.to_csv(OUTPUT_FILENAME, index=False, encoding='utf-8-sig')\n",
    "        print(f\"\\n✅ 성공! '{OUTPUT_FILENAME}' 파일로 모든 실패 ID를 통합 저장했습니다.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ 오류: 최종 파일을 저장하는 중 문제가 발생했습니다: {e}\")\n",
    "\n",
    "\n",
    "# 메인 함수 실행\n",
    "if __name__ == \"__main__\":\n",
    "    merge_failure_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1586bd",
   "metadata": {},
   "source": [
    "중앙부처 실패id 재크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f9c4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import ssl\n",
    "import time\n",
    "from requests.adapters import HTTPAdapter\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- 💡 1. 여기에 모든 API 키를 입력하세요 ---\n",
    "API_KEYS = [\n",
    "    \"0f561bd1f21a64f960fff4cf634d3afeb996d252a52dae3c7fea3c70c2c9ba09\",\n",
    "    \"6c00ed313ec5456c58b8d55a6f5d12a65cd4984956e87be30c7a3ea22b8ca086\"\n",
    "    # 가지고 있는 모든 키를 추가할 수 있습니다.\n",
    "]\n",
    "\n",
    "# --- 💡 2. 입력 파일과 결과 파일 이름 설정 ---\n",
    "INPUT_FILE = \"통합_실패_ID_목록.csv\"\n",
    "ID_COLUMN = \"서비스ID\" # 통합 실패 파일의 ID 컬럼명\n",
    "\n",
    "OUTPUT_SUCCESS_FILE = \"최종_재시도_성공.csv\"\n",
    "OUTPUT_FAILURE_FILE = \"최종_재시도_실패.csv\"\n",
    "\n",
    "# --- API 호출 설정 (수정 필요 없음) ---\n",
    "BASE_URL = \"https://www.bokjiro.go.kr/ssis-tbu/TWAT52005M/twataa/wlfareInfo/selectWlfareInfo.do\"\n",
    "\n",
    "# (이 아래 TLSAdapter, session 설정은 기존과 동일합니다)\n",
    "class TLSAdapter(HTTPAdapter):\n",
    "    def init_poolmanager(self, *args, **kwargs):\n",
    "        ctx = ssl.create_default_context(ssl.Purpose.SERVER_AUTH)\n",
    "        ctx.minimum_version = ssl.TLSVersion.TLSv1_2\n",
    "        kwargs['ssl_context'] = ctx\n",
    "        return super().init_poolmanager(*args, **kwargs)\n",
    "\n",
    "session = requests.Session()\n",
    "session.mount(\"https://\", TLSAdapter())\n",
    "\n",
    "# (XML 파싱 함수는 기존과 동일합니다)\n",
    "def parse_service_detail(xml_text):\n",
    "    try:\n",
    "        root = ET.fromstring(xml_text)\n",
    "        node = root if root.tag == \"wantedDtl\" else root.find(\".//wantedDtl\")\n",
    "        if node is None:\n",
    "            return None\n",
    "        return {\n",
    "            \"서비스ID\": node.findtext(\"servId\", \"\"), \"서비스명\": node.findtext(\"servNm\", \"\"),\n",
    "            \"소관부처\": node.findtext(\"jurMnofNm\", \"\"), \"서비스개요\": node.findtext(\"wlfareInfoOutlCn\", \"\"),\n",
    "            \"지원대상상세\": node.findtext(\"tgtrDtlCn\", \"\").strip(), \"선정기준\": node.findtext(\"slctCritCn\", \"\").strip(),\n",
    "            \"지원내용\": node.findtext(\"alwServCn\", \"\").strip(), \"지원주기\": node.findtext(\"sprtCycNm\", \"\"),\n",
    "            \"지급방식\": node.findtext(\"srvPvsnNm\", \"\"),\n",
    "        }\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def fetch_service_detail(sid, api_key):\n",
    "    \"\"\"지정된 API 키로 서비스 상세 정보를 요청합니다.\"\"\"\n",
    "    params = {\"serviceKey\": api_key, \"servId\": sid}\n",
    "    try:\n",
    "        resp = session.get(BASE_URL, params=params, timeout=30)\n",
    "        # API 한도 초과 에러는 보통 특정 문자열을 포함한 응답을 줍니다.\n",
    "        # 실제 응답에 따라 'LIMIT_EXCEEDED' 또는 다른 문자열로 변경해야 할 수 있습니다.\n",
    "        if \"SERVICE KEY IS NOT REGISTERED\" in resp.text or \"LIMITED\" in resp.text:\n",
    "             return \"LIMIT_EXCEEDED\"\n",
    "        return resp.text if resp.status_code == 200 else None\n",
    "    except requests.exceptions.RequestException:\n",
    "        return None\n",
    "\n",
    "# --- 최종 실행 로직 ---\n",
    "def run_final_retry():\n",
    "    # 1. 재시도할 ID 목록 불러오기\n",
    "    try:\n",
    "        df = pd.read_csv(INPUT_FILE)\n",
    "        service_ids = df[ID_COLUMN].dropna().astype(str).tolist()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"❌ 입력 파일 '{INPUT_FILE}'을 찾을 수 없습니다. 스크립트와 같은 폴더에 있는지 확인하세요.\")\n",
    "        return\n",
    "\n",
    "    # 2. 실행 시작\n",
    "    print(f\"✅ 총 {len(service_ids)}개의 실패 ID에 대한 최종 재시도를 시작합니다.\")\n",
    "    print(f\"🔑 사용 가능한 API 키: {len(API_KEYS)}개\")\n",
    "\n",
    "    successful_rows = []\n",
    "    failed_ids = []\n",
    "    \n",
    "    current_key_index = 0\n",
    "    pbar = tqdm(total=len(service_ids), desc=\"ID 처리 중\")\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(service_ids):\n",
    "        sid = service_ids[i]\n",
    "        \n",
    "        if current_key_index >= len(API_KEYS):\n",
    "            print(\"\\n⚠️ 모든 API 키의 사용 한도에 도달했거나 유효하지 않습니다. 작업을 중단합니다.\")\n",
    "            failed_ids.extend(service_ids[i:]) # 남은 ID는 모두 실패로 처리\n",
    "            pbar.update(len(service_ids) - i)\n",
    "            break\n",
    "\n",
    "        api_key = API_KEYS[current_key_index]\n",
    "        xml_text = fetch_service_detail(sid, api_key)\n",
    "\n",
    "        if xml_text == \"LIMIT_EXCEEDED\":\n",
    "            print(f\"\\n🔑 API 키 {current_key_index + 1}의 한도에 도달. 다음 키로 전환합니다.\")\n",
    "            current_key_index += 1\n",
    "            continue  # 현재 ID(sid)를 다음 키로 다시 시도하기 위해 i를 증가시키지 않음\n",
    "\n",
    "        elif xml_text is None:\n",
    "            failed_ids.append(sid)\n",
    "            pbar.set_postfix_str(f\"{sid} 요청 실패\")\n",
    "            i += 1\n",
    "            pbar.update(1)\n",
    "\n",
    "        else:\n",
    "            data = parse_service_detail(xml_text)\n",
    "            if data:\n",
    "                successful_rows.append(data)\n",
    "            else:\n",
    "                failed_ids.append(sid)\n",
    "            pbar.set_postfix_str(f\"{sid} 처리 완료\")\n",
    "            i += 1\n",
    "            pbar.update(1)\n",
    "            \n",
    "        time.sleep(0.3) # 서버 부하 감소\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "    # 3. 결과 저장\n",
    "    if successful_rows:\n",
    "        pd.DataFrame(successful_rows).to_csv(OUTPUT_SUCCESS_FILE, index=False, encoding=\"utf-8-sig\")\n",
    "        print(f\"\\n💾 재시도 성공: {len(successful_rows)}건을 '{OUTPUT_SUCCESS_FILE}' 파일로 저장했습니다.\")\n",
    "    \n",
    "    if failed_ids:\n",
    "        pd.DataFrame(failed_ids, columns=[\"재실패ID\"]).to_csv(OUTPUT_FAILURE_FILE, index=False)\n",
    "        print(f\"💾 재시도 실패: {len(failed_ids)}건을 '{OUTPUT_FAILURE_FILE}' 파일로 저장했습니다.\")\n",
    "        \n",
    "    print(\"\\n🎉 모든 작업이 완료되었습니다.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_final_retry()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79988cd5",
   "metadata": {},
   "source": [
    "중앙부처 csv파일 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2244b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "files = ['중앙부처_1.csv', '중앙부처_2.csv']\n",
    "\n",
    "dfs = [pd.read_csv(f) for f in files]\n",
    "merged_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "merged_df.to_csv(\"중앙부처_1,2합본.csv\", index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"✅ 통합 완료 → 중앙부처_1,2합본.csv\")\n",
    "print(f\"총 행 개수: {len(merged_df)}\")\n",
    "print(f\"컬럼: {list(merged_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe8c066",
   "metadata": {},
   "source": [
    "중앙부처 합본 -2차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b7702e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- 설정 ---\n",
    "\n",
    "# 1. 기존에 작업했던 합본 파일 이름\n",
    "MAIN_CSV_FILE = \"중앙부처_1,2합본.csv\"\n",
    "\n",
    "# 2. 폴더에서 찾을 XML 파일 패턴\n",
    "XML_PATTERN = \"*.xml\"\n",
    "\n",
    "# 3. 최종적으로 모든 데이터가 합쳐져 저장될 파일 이름\n",
    "FINAL_OUTPUT_FILE = \"최종_중앙부처_통합본.csv\"\n",
    "\n",
    "# --- XML 파싱 함수 (기존 코드와 동일) ---\n",
    "def parse_service_detail(xml_text):\n",
    "    \"\"\"XML 텍스트를 입력받아 파싱하고, 데이터 딕셔너리를 반환합니다.\"\"\"\n",
    "    try:\n",
    "        root = ET.fromstring(xml_text)\n",
    "        node = root if root.tag == \"wantedDtl\" else root.find(\".//wantedDtl\")\n",
    "        if node is None:\n",
    "            return None\n",
    "        return {\n",
    "            \"서비스ID\": node.findtext(\"servId\", \"\"),\n",
    "            \"서비스명\": node.findtext(\"servNm\", \"\"),\n",
    "            \"소관부처\": node.findtext(\"jurMnofNm\", \"\"),\n",
    "            \"서비스개요\": node.findtext(\"wlfareInfoOutlCn\", \"\"),\n",
    "            \"지원대상상세\": node.findtext(\"tgtrDtlCn\", \"\").strip(),\n",
    "            \"선정기준\": node.findtext(\"slctCritCn\", \"\").strip(),\n",
    "            \"지원내용\": node.findtext(\"alwServCn\", \"\").strip(),\n",
    "            \"지원주기\": node.findtext(\"sprtCycNm\", \"\"),\n",
    "            \"지급방식\": node.findtext(\"srvPvsnNm\", \"\"),\n",
    "        }\n",
    "    except ET.ParseError:\n",
    "        # XML 형식이 잘못된 경우\n",
    "        return None\n",
    "\n",
    "# --- 메인 실행 로직 ---\n",
    "def process_and_merge_files():\n",
    "    # 1. XML 파일 목록 찾기\n",
    "    xml_files = glob.glob(XML_PATTERN)\n",
    "    if not xml_files:\n",
    "        print(f\"❌ 오류: 폴더에서 '{XML_PATTERN}' 패턴에 맞는 XML 파일을 찾을 수 없습니다.\")\n",
    "        return\n",
    "\n",
    "    print(f\"📁 총 {len(xml_files)}개의 XML 파일을 찾았습니다. 파싱을 시작합니다...\")\n",
    "\n",
    "    # 2. 각 XML 파일을 파싱하여 데이터 리스트 생성\n",
    "    recovered_data = []\n",
    "    for file_path in tqdm(xml_files, desc=\"XML 파일 처리 중\"):\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "                # 파일 내용이 비어있지 않은 경우에만 파싱 시도\n",
    "                if content.strip():\n",
    "                    data = parse_service_detail(content)\n",
    "                    if data:\n",
    "                        recovered_data.append(data)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ 경고: '{file_path}' 파일 처리 중 오류 발생. 건너뜁니다. ({e})\")\n",
    "            \n",
    "    if not recovered_data:\n",
    "        print(\"❌ 오류: XML 파일에서 유효한 데이터를 추출하지 못했습니다.\")\n",
    "        return\n",
    "        \n",
    "    recovered_df = pd.DataFrame(recovered_data)\n",
    "    print(f\"✅ {len(recovered_df)}개의 서비스 데이터를 XML 파일로부터 성공적으로 복구했습니다.\")\n",
    "\n",
    "    # 3. 기존 합본 CSV 파일 불러오기\n",
    "    try:\n",
    "        print(f\"\\n기존 합본 파일 '{MAIN_CSV_FILE}'을 불러옵니다...\")\n",
    "        main_df = pd.read_csv(MAIN_CSV_FILE)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"❌ 오류: '{MAIN_CSV_FILE}' 파일을 찾을 수 없습니다. 파일이 스크립트와 같은 폴더에 있는지 확인하세요.\")\n",
    "        return\n",
    "\n",
    "    # 4. 복구된 데이터와 기존 데이터 병합\n",
    "    print(\"복구된 데이터와 기존 데이터를 병합합니다...\")\n",
    "    final_df = pd.concat([main_df, recovered_df], ignore_index=True)\n",
    "    \n",
    "    initial_rows = len(final_df)\n",
    "    print(f\"  - 병합 후 총 행 개수: {initial_rows}개\")\n",
    "\n",
    "    # 5. 서비스ID 기준으로 중복 데이터 제거 (복구된 데이터가 우선순위를 가짐)\n",
    "    final_df.drop_duplicates(subset=['서비스ID'], keep='last', inplace=True)\n",
    "    final_rows = len(final_df)\n",
    "    print(f\"  - 중복 제거 후 최종 행 개수: {final_rows}개 ({initial_rows - final_rows}개 중복 제거)\")\n",
    "\n",
    "    # 6. 최종 결과를 새 파일로 저장\n",
    "    try:\n",
    "        final_df.to_csv(FINAL_OUTPUT_FILE, index=False, encoding='utf-8-sig')\n",
    "        print(f\"\\n🎉 성공! 최종 통합된 데이터를 '{FINAL_OUTPUT_FILE}' 파일로 저장했습니다.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ 오류: 최종 파일을 저장하는 중 문제가 발생했습니다: {e}\")\n",
    "\n",
    "# --- 스크립트 실행 ---\n",
    "if __name__ == \"__main__\":\n",
    "    process_and_merge_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769acd72",
   "metadata": {},
   "source": [
    "중앙부처 합본-3차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f76521",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "files = ['중앙부처_1.csv', '중앙부처_2.csv']\n",
    "\n",
    "dfs = [pd.read_csv(f) for f in files]\n",
    "merged_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "merged_df.to_csv(\"중앙부처_1,2합본.csv\", index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"✅ 통합 완료 → 중앙부처_1,2합본.csv\")\n",
    "print(f\"총 행 개수: {len(merged_df)}\")\n",
    "print(f\"컬럼: {list(merged_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b950179",
   "metadata": {},
   "source": [
    "## 지자체 파일 크롤링-복지로사이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6d8dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# 입력 CSV 파일\n",
    "MASTER_CSV = \"지자체_복지서비스리스트_통합.csv\"\n",
    "SERVICE_ID_COLUMN = \"서비스ID\"\n",
    "\n",
    "# URL 포맷\n",
    "URL_TEMPLATE = \"https://www.bokjiro.go.kr/ssis-tbu/twataa/wlfareInfo/moveTWAT52011M.do?wlfareInfoId={}&wlfareInfoReldBztpCd=02\"\n",
    "\n",
    "def scrape_service(driver, service_id):\n",
    "    \"\"\"단일 서비스 ID 크롤링\"\"\"\n",
    "    url = URL_TEMPLATE.format(service_id)\n",
    "    details = {\n",
    "        \"서비스ID\": service_id,\n",
    "        \"카테고리\": \"\",\n",
    "        \"지원대상\": \"\",\n",
    "        \"선정기준\": \"\",\n",
    "        \"서비스내용\": \"\",\n",
    "        \"신청방법\": \"\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "\n",
    "        # 로딩 대기\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"div.cl-text\"))\n",
    "        )\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "        # 카테고리 추출\n",
    "        categories = []\n",
    "        category_divs = soup.find_all(\"div\", class_=\"cl-text\", style=lambda x: x and \"vertical-align:inherit\" in x)\n",
    "        for div in category_divs:\n",
    "            txt = div.get_text(strip=True)\n",
    "            if txt not in [\"지원대상\", \"선정기준\", \"서비스 내용\", \"신청방법\"]:  # 본문 키 제외\n",
    "                categories.append(txt)\n",
    "        details[\"카테고리\"] = \", \".join(categories)\n",
    "\n",
    "        # 본문 추출\n",
    "        mapping = {\n",
    "            \"지원대상\": \"지원대상\",\n",
    "            \"선정기준\": \"선정기준\",\n",
    "            \"서비스 내용\": \"서비스내용\",\n",
    "            \"신청방법\": \"신청방법\"\n",
    "        }\n",
    "        for title_div in soup.find_all(\"div\", class_=\"cl-text\"):\n",
    "            title = title_div.get_text(strip=True)\n",
    "            if title in mapping:\n",
    "                content_div = title_div.find_next(\"div\", style=lambda x: x and \"overflow:hidden\" in x)\n",
    "                if content_div:\n",
    "                    details[mapping[title]] = content_div.get_text(\" \", strip=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 오류 (ID: {service_id}): {e}\")\n",
    "\n",
    "    return details\n",
    "\n",
    "\n",
    "def get_resume_point(batch_prefix=\"지자체_복지서비스_크롤링결과_batch\"):\n",
    "    \"\"\"마지막 저장된 배치 파일을 찾아 이어하기 시작점 반환\"\"\"\n",
    "    batch_files = [f for f in os.listdir() if f.startswith(batch_prefix) and f.endswith(\".csv\")]\n",
    "    if not batch_files:\n",
    "        return 0, 1  # (시작 index, 다음 batch 번호)\n",
    "\n",
    "    batch_files.sort()\n",
    "    last_file = batch_files[-1]\n",
    "    print(f\"📂 마지막 저장된 파일: {last_file}\")\n",
    "\n",
    "    try:\n",
    "        df_last = pd.read_csv(last_file)\n",
    "        if not df_last.empty:\n",
    "            last_id = df_last[\"서비스ID\"].iloc[-1]\n",
    "            print(f\"👉 마지막 저장된 서비스ID: {last_id}\")\n",
    "            return df_last.index[-1] + 1 + (len(batch_files)-1)*100, len(batch_files)+1\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ 이어하기 파일 분석 중 오류: {e}\")\n",
    "\n",
    "    return 0, 1\n",
    "\n",
    "\n",
    "def main(batch_size=100):\n",
    "    # 서비스ID 목록 불러오기\n",
    "    df_master = pd.read_csv(MASTER_CSV)\n",
    "    service_ids = df_master[SERVICE_ID_COLUMN].dropna().astype(str).tolist()\n",
    "\n",
    "    # 이어하기 시작점 확인\n",
    "    start_idx, batch_num = get_resume_point()\n",
    "    if start_idx >= len(service_ids):\n",
    "        print(\"🎉 모든 서비스ID에 대한 크롤링이 이미 완료되었습니다.\")\n",
    "        return\n",
    "\n",
    "    # 크롬 드라이버 준비\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--start-maximized\")\n",
    "    service = ChromeService(ChromeDriverManager().install())\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "    results = []\n",
    "    last_id = None\n",
    "\n",
    "    for idx, sid in enumerate(service_ids[start_idx:], start=start_idx+1):\n",
    "        print(f\"[{idx}/{len(service_ids)}] 크롤링 중: {sid}\")\n",
    "        data = scrape_service(driver, sid)\n",
    "        results.append(data)\n",
    "        last_id = sid\n",
    "\n",
    "        # 100개 단위 저장\n",
    "        if idx % batch_size == 0:\n",
    "            out_df = pd.DataFrame(results)\n",
    "            out_df.to_csv(f\"지자체_복지서비스_크롤링결과_batch{batch_num}.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "            print(f\"💾 Batch {batch_num} 저장 완료 ({len(results)}개)\")\n",
    "            batch_num += 1\n",
    "            results = []\n",
    "\n",
    "        time.sleep(0.5)  # 서버 부하 방지\n",
    "\n",
    "    # 마지막 남은 결과 저장\n",
    "    if results:\n",
    "        out_df = pd.DataFrame(results)\n",
    "        out_df.to_csv(f\"지자체_복지서비스_크롤링결과_batch{batch_num}.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "        print(f\"💾 Batch {batch_num} 저장 완료 ({len(results)}개)\")\n",
    "\n",
    "    driver.quit()\n",
    "    print(f\"✅ 마지막 저장된 서비스ID: {last_id}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d5a90f",
   "metadata": {},
   "source": [
    "지자체 크롤링 통합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a566c187",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# 합칠 파일 패턴 지정\n",
    "file_list = sorted(glob.glob(\"지자체_복지서비스_크롤링결과_batch*.csv\"))\n",
    "\n",
    "print(f\"총 {len(file_list)}개 파일을 병합합니다.\")\n",
    "\n",
    "# 파일 읽어서 합치기\n",
    "dfs = [pd.read_csv(f) for f in file_list]\n",
    "merged_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# 최종 저장\n",
    "merged_df.to_csv(\"지자체_복지서비스_크롤링결과_통합본.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"✅ 병합 완료: 지자체_복지서비스_크롤링결과_통합본.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fd61d1",
   "metadata": {},
   "source": [
    "지자체 csv 통합 - 세부내용 + 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59b4208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 파일 불러오기\n",
    "base_df = pd.read_csv(\"지자체_복지서비스리스트_통합.csv\", encoding=\"utf-8-sig\")\n",
    "crawl_df = pd.read_csv(\"지자체_복지서비스_크롤링결과_통합본.csv\", encoding=\"utf-8-sig\")\n",
    "\n",
    "# 서비스ID 기준 병합 (좌측 기준)\n",
    "merged_df = pd.merge(base_df, crawl_df, on=\"서비스ID\", how=\"left\")\n",
    "\n",
    "# 저장 (최종 파일 이름 지정)\n",
    "output_file = \"local_final_welfare_list.csv\"\n",
    "merged_df.to_csv(output_file, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"✅ 병합 완료: {output_file}\")\n",
    "print(f\"총 행 수: {len(merged_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98b89f2",
   "metadata": {},
   "source": [
    "## 민간복지리스트 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c11ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "URL = \"https://www.bokjiro.go.kr/ssis-tbu/TWAT52005M/twataa/wlfareInfo/selectWlfareInfo.do\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36\",\n",
    "    \"Referer\": \"https://www.bokjiro.go.kr/ssis-tbu/twataa/wlfareInfo/moveTWAT52005M.do\",\n",
    "    \"Content-Type\": \"application/json;charset=UTF-8\",\n",
    "}\n",
    "\n",
    "def fetch_page(page: int):\n",
    "    payload = {\n",
    "        \"dmSearchParam\": {\n",
    "            \"page\": str(page),\n",
    "            \"orderBy\": \"date\",\n",
    "            \"tabId\": \"3\",   # ✅ 민간 탭\n",
    "            \"searchTerm\": \"\",\n",
    "            \"onlineYn\": \"\",\n",
    "            \"bkjrLftmCycCd\": \"\",\n",
    "            \"daesang\": \"\",\n",
    "            \"period\": \"\",\n",
    "            \"age\": \"\",\n",
    "            \"region\": \"\",\n",
    "            \"jjim\": \"\",\n",
    "            \"subject\": \"\",\n",
    "            \"favoriteKeyword\": \"Y\",\n",
    "            \"sido\": \"\",\n",
    "            \"gungu\": \"\",\n",
    "            \"endYn\": \"N\"\n",
    "        },\n",
    "        \"dmScr\": {\n",
    "            \"curScrId\": \"tbu/app/twat/twata/twataa/TWAT52005M\",\n",
    "            \"befScrId\": \"\"\n",
    "        }\n",
    "    }\n",
    "    res = requests.post(URL, headers=headers, json=payload)\n",
    "    res.raise_for_status()\n",
    "    return res.json().get(\"dsServiceList3\", [])\n",
    "\n",
    "# ✅ 전체 페이지 크롤링\n",
    "all_data = []\n",
    "for page in range(1, 39):  # 1~38 페이지\n",
    "    data = fetch_page(page)\n",
    "    print(f\"{page}페이지: {len(data)}건 수집\")\n",
    "    all_data.extend(data)\n",
    "    time.sleep(0.3)\n",
    "\n",
    "print(\"총 민간 데이터:\", len(all_data))\n",
    "\n",
    "# ✅ 기본 필드 + RETURN_STR 세부항목 파싱\n",
    "rows = []\n",
    "for svc in all_data:\n",
    "    base_info = {\n",
    "        \"서비스ID\": svc.get(\"WLFARE_INFO_ID\"),\n",
    "        \"서비스명\": svc.get(\"WLFARE_INFO_NM\"),\n",
    "        \"서비스 요약\": svc.get(\"WLFARE_INFO_OUTL_CN\"),\n",
    "        \"상세 링크\": f\"https://www.bokjiro.go.kr/ssis-tbu/twataa/wlfareInfo/moveTWAT52011M.do?wlfareInfoId={svc.get('WLFARE_INFO_ID')}&wlfareInfoReldBztpCd=03\",\n",
    "        \"소관기관\": svc.get(\"BIZ_CHR_INST_NM\"),\n",
    "        \"대표연락처\": svc.get(\"RPRS_CTADR\"),\n",
    "        \"신청가능여부\": svc.get(\"ONLINEYN\"),\n",
    "        \"주소\": svc.get(\"ADDR\"),\n",
    "        \"태그\": svc.get(\"TAG_NM\"),\n",
    "        \"시작일\": svc.get(\"ENFC_BGNG_YMD\"),\n",
    "        \"종료일\": svc.get(\"ENFC_END_YMD\"),\n",
    "        \"진행상태\": svc.get(\"CVL_PROGRSS_STATUS\"),\n",
    "    }\n",
    "    \n",
    "    # RETURN_STR 파싱\n",
    "    return_str = svc.get(\"RETURN_STR\", \"\")\n",
    "    parsed_info = {}\n",
    "    if return_str:\n",
    "        for item in return_str.split(\";\"):\n",
    "            if \":\" in item:\n",
    "                k, v = item.split(\":\", 1)\n",
    "                parsed_info[k.strip()] = v.strip()\n",
    "    \n",
    "    # 기본정보 + RETURN_STR 확장정보 병합\n",
    "    rows.append({**base_info, **parsed_info})\n",
    "\n",
    "# ✅ CSV 저장\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(\"민간_복지서비스_확장.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"📁 민간_복지서비스_확장.csv 저장 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58bce38",
   "metadata": {},
   "source": [
    "민간복지 상세내역 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef99aa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# 입력 CSV 파일\n",
    "MASTER_CSV = \"민간_복지서비스_확장.csv\"   # 민간 서비스 ID 들어있는 파일\n",
    "SERVICE_ID_COLUMN = \"서비스ID\"\n",
    "\n",
    "# URL 포맷\n",
    "URL_TEMPLATE = \"https://www.bokjiro.go.kr/ssis-tbu/twataa/wlfareInfo/moveTWAT52015M.do?wlfareInfoId={}&wlfareInfoReldBztpCd=03\"\n",
    "\n",
    "def scrape_service(driver, service_id):\n",
    "    \"\"\"단일 민간 서비스 ID 상세 크롤링\"\"\"\n",
    "    url = URL_TEMPLATE.format(service_id)\n",
    "    details = {\n",
    "        \"서비스ID\": service_id,\n",
    "        \"카테고리\": \"\",\n",
    "        \"사업상태\": \"\",\n",
    "        \"사업기간\": \"\",\n",
    "        \"연락처\": \"\",\n",
    "        \"이메일\": \"\",\n",
    "        \"사업목적\": \"\",\n",
    "        \"지원대상\": \"\",\n",
    "        \"지원내용\": \"\",\n",
    "        \"신청방법\": \"\",\n",
    "        \"제출서류\": \"\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "\n",
    "        # 로딩 대기\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"div.cl-text\"))\n",
    "        )\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "        # ✅ 카테고리 (상단 badge-wlfare 영역)\n",
    "        category_divs = soup.select(\"div.badge-wlfare div.cl-text\")\n",
    "        categories = [c.get_text(strip=True) for c in category_divs if c.get_text(strip=True)]\n",
    "        details[\"카테고리\"] = \", \".join(categories)\n",
    "\n",
    "        # ✅ 단일 필드 (사업상태, 사업기간, 연락처, 이메일)\n",
    "        mapping_simple = {\n",
    "            \"사업상태\": \"사업상태\",\n",
    "            \"사업기간\": \"사업기간\",\n",
    "            \"연락처\": \"연락처\",\n",
    "            \"이메일\": \"이메일\"\n",
    "        }\n",
    "        for title, col in mapping_simple.items():\n",
    "            title_div = soup.find(\"div\", class_=\"cl-text\", string=title)\n",
    "            if title_div:\n",
    "                sibling_div = title_div.find_parent().find_next_sibling(\"div\")\n",
    "                if sibling_div and \"cl-text\" in sibling_div.get(\"class\", []):\n",
    "                    details[col] = sibling_div.get_text(\" \", strip=True)\n",
    "\n",
    "        # ✅ 본문 필드 (사업목적, 지원대상, 지원내용, 신청방법, 제출서류)\n",
    "        mapping_long = {\n",
    "            \"사업목적\": \"사업목적\",\n",
    "            \"지원대상\": \"지원대상\",\n",
    "            \"지원내용\": \"지원내용\",\n",
    "            \"신청방법\": \"신청방법\",\n",
    "            \"제출서류\": \"제출서류\"\n",
    "        }\n",
    "        for title, col in mapping_long.items():\n",
    "            title_div = soup.find(\"div\", class_=\"cl-text\", string=title)\n",
    "            if title_div:\n",
    "                content_block = title_div.find_parent().find_next(\"div\", class_=\"cl-control\")\n",
    "                if content_block:\n",
    "                    text_div = content_block.find(\"div\", class_=\"cl-text\")\n",
    "                    if text_div:\n",
    "                        details[col] = text_div.get_text(\"\\n\", strip=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 오류 (ID: {service_id}): {e}\")\n",
    "\n",
    "    return details\n",
    "\n",
    "\n",
    "def get_resume_point(batch_prefix=\"민간_복지서비스_크롤링결과_batch\"):\n",
    "    \"\"\"마지막 저장된 배치 파일을 찾아 이어하기 시작점 반환\"\"\"\n",
    "    batch_files = [f for f in os.listdir() if f.startswith(batch_prefix) and f.endswith(\".csv\")]\n",
    "    if not batch_files:\n",
    "        return 0, 1  # (시작 index, 다음 batch 번호)\n",
    "\n",
    "    batch_files.sort()\n",
    "    last_file = batch_files[-1]\n",
    "    print(f\"📂 마지막 저장된 파일: {last_file}\")\n",
    "\n",
    "    try:\n",
    "        df_last = pd.read_csv(last_file)\n",
    "        if not df_last.empty:\n",
    "            last_id = df_last[\"서비스ID\"].iloc[-1]\n",
    "            print(f\"👉 마지막 저장된 서비스ID: {last_id}\")\n",
    "            return df_last.index[-1] + 1 + (len(batch_files)-1)*100, len(batch_files)+1\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ 이어하기 파일 분석 중 오류: {e}\")\n",
    "\n",
    "    return 0, 1\n",
    "\n",
    "\n",
    "def main(batch_size=100):\n",
    "    # 서비스ID 목록 불러오기\n",
    "    df_master = pd.read_csv(MASTER_CSV)\n",
    "    service_ids = df_master[SERVICE_ID_COLUMN].dropna().astype(str).tolist()\n",
    "\n",
    "    # 이어하기 시작점 확인\n",
    "    start_idx, batch_num = get_resume_point()\n",
    "    if start_idx >= len(service_ids):\n",
    "        print(\"🎉 모든 서비스ID에 대한 크롤링이 이미 완료되었습니다.\")\n",
    "        return\n",
    "\n",
    "    # 크롬 드라이버 준비\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--start-maximized\")\n",
    "    service = ChromeService(ChromeDriverManager().install())\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "    results = []\n",
    "    last_id = None\n",
    "\n",
    "    for idx, sid in enumerate(service_ids[start_idx:], start=start_idx+1):\n",
    "        print(f\"[{idx}/{len(service_ids)}] 크롤링 중: {sid}\")\n",
    "        data = scrape_service(driver, sid)\n",
    "        results.append(data)\n",
    "        last_id = sid\n",
    "\n",
    "        # 100개 단위 저장\n",
    "        if idx % batch_size == 0:\n",
    "            out_df = pd.DataFrame(results)\n",
    "            out_df.to_csv(f\"민간_복지서비스_크롤링결과_batch{batch_num}.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "            print(f\"💾 Batch {batch_num} 저장 완료 ({len(results)}개)\")\n",
    "            batch_num += 1\n",
    "            results = []\n",
    "\n",
    "        time.sleep(0.5)  # 서버 부하 방지\n",
    "\n",
    "    # 마지막 남은 결과 저장\n",
    "    if results:\n",
    "        out_df = pd.DataFrame(results)\n",
    "        out_df.to_csv(f\"민간_복지서비스_크롤링결과_batch{batch_num}.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "        print(f\"💾 Batch {batch_num} 저장 완료 ({len(results)}개)\")\n",
    "\n",
    "    driver.quit()\n",
    "    print(f\"✅ 마지막 저장된 서비스ID: {last_id}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f6a011",
   "metadata": {},
   "source": [
    "파일 합치기 - 상세내역만 나온것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6421cf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# 병합할 파일 패턴\n",
    "file_pattern = \"민간_복지서비스_크롤링결과_batch*.csv\"\n",
    "\n",
    "# 모든 배치 파일 경로 가져오기\n",
    "files = sorted(glob.glob(file_pattern))\n",
    "\n",
    "print(\"📂 합칠 파일:\", files)\n",
    "\n",
    "# 파일 읽어서 세로로 이어붙이기\n",
    "dfs = [pd.read_csv(f) for f in files]\n",
    "merged_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# 저장\n",
    "output_file = \"민간_복지서비스_크롤링결과_total.csv\"\n",
    "merged_df.to_csv(output_file, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"✅ 저장 완료: {output_file}, 총 {len(merged_df)} 행\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4304c70f",
   "metadata": {},
   "source": [
    "리스트 + 상세내역"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26984e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 파일 경로\n",
    "base_file = \"민간_복지서비스_확장.csv\"          # 기준 파일\n",
    "crawl_file = \"민간_복지서비스_크롤링결과_total.csv\"  # 크롤링 결과 파일\n",
    "output_file = \"private_final_welfare_list.csv\"\n",
    "\n",
    "# CSV 읽기\n",
    "df_base = pd.read_csv(base_file)\n",
    "df_crawl = pd.read_csv(crawl_file)\n",
    "\n",
    "# 기준 컬럼명 확인\n",
    "print(\"기준 파일 컬럼:\", df_base.columns.tolist())\n",
    "print(\"크롤링 파일 컬럼:\", df_crawl.columns.tolist())\n",
    "\n",
    "# 서비스ID 기준으로 병합 (오른쪽 방향으로 붙이기)\n",
    "df_merged = pd.merge(df_base, df_crawl, on=\"서비스ID\", how=\"left\")\n",
    "\n",
    "# 저장\n",
    "df_merged.to_csv(output_file, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"✅ 병합 완료! 저장된 파일: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2c014b",
   "metadata": {},
   "source": [
    "# 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4186114d",
   "metadata": {},
   "source": [
    "## local_welfare 전처리정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f8c474",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# CSV 불러오기\n",
    "file_path = \"local_final_welfare_list.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# ==========================\n",
    "# 1. 카테고리 컬럼 불필요한 값 제거\n",
    "# ==========================\n",
    "remove_list = [\n",
    "    \"화면크기\", \"님\", \"로그아웃까지 남은 시간\", \"30:00\",\n",
    "    \"대한민국 국민 누구나!\", \"지자체 복지서비스\", \"찜하기\",\n",
    "    \"최종 수정일(반영일)\", \"지원주기\", \"제공유형\", \"처리절차\"\n",
    "]\n",
    "\n",
    "def clean_category(val):\n",
    "    if pd.isna(val):\n",
    "        return val\n",
    "    items = [x.strip() for x in str(val).split(\",\")]\n",
    "    filtered = []\n",
    "    for x in items:\n",
    "        if len(x) == 10 and x[4] == \"-\" and x[7] == \"-\":\n",
    "            continue\n",
    "        if \"회성\" in x:\n",
    "            continue\n",
    "        if any(r == x or r in x for r in remove_list):\n",
    "            continue\n",
    "        filtered.append(x)\n",
    "    return \", \".join(filtered)\n",
    "\n",
    "df[\"카테고리\"] = df[\"카테고리\"].apply(clean_category)\n",
    "\n",
    "# ==========================\n",
    "# 2. 신청방법_x → 신청환경\n",
    "# ==========================\n",
    "if \"신청방법_x\" in df.columns:\n",
    "    df.rename(columns={\"신청방법_x\": \"신청환경\"}, inplace=True)\n",
    "\n",
    "    def normalize_env(val):\n",
    "        if pd.isna(val):\n",
    "            return val\n",
    "        val = str(val).replace(\" \", \"\")\n",
    "        if \"방문\" in val and \"인터넷\" in val:\n",
    "            return \"ALL\"\n",
    "        elif \"방문\" in val:\n",
    "            return \"방문\"\n",
    "        elif \"인터넷\" in val:\n",
    "            return \"인터넷\"\n",
    "        return val\n",
    "\n",
    "    df[\"신청환경\"] = df[\"신청환경\"].apply(normalize_env)\n",
    "\n",
    "# ==========================\n",
    "# 3. 신청방법_y → 신청방법상세\n",
    "# ==========================\n",
    "if \"신청방법_y\" in df.columns:\n",
    "    df.rename(columns={\"신청방법_y\": \"신청방법상세\"}, inplace=True)\n",
    "\n",
    "    def clean_detail(val):\n",
    "        if pd.isna(val):\n",
    "            return val\n",
    "        text = str(val).strip()\n",
    "        # 맨 앞 \"-\" 제거\n",
    "        text = re.sub(r\"^-\\s*\", \"\", text)\n",
    "        # 나머지 \"-\" 를 \",\" 로 변환\n",
    "        text = text.replace(\"-\", \",\")\n",
    "        return text.strip()\n",
    "\n",
    "    df= df.applymap(lambda x: clean_detail(x))\n",
    "\n",
    "# ==========================\n",
    "# 저장\n",
    "# ==========================\n",
    "output_path = \"local_final_welfare_list_cleaned_copied.csv\"\n",
    "df.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"✅ 전처리 완료! 저장된 파일:\", output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42e3c5c",
   "metadata": {},
   "source": [
    "칼럼 맞추기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5ce0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 불러오기\n",
    "file_path = \"local_final_welfare_list_cleaned_copied.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 카테고리 사전 정의 (키워드 매핑)\n",
    "category_keywords = {\n",
    "    \"생계지원\": [\"식비\", \"주거비\", \"공과금\", \"차상위\", \"생활비\", \"긴급복지\", \"할인\"],\n",
    "    \"돌봄·보호\": [\"간병\", \"시설보호\", \"주야간\", \"보호자\", \"양육\", \"간호\"],\n",
    "    \"건강·의료\": [\"질병\", \"진단\", \"치료\", \"의료비\", \"병원\", \"임신\", \"출산\"],\n",
    "    \"일상생활\": [\"가사\", \"식사\", \"이동\", \"위생\", \"생활지원\"],\n",
    "    \"안전위기\": [\"폭력\", \"학대\", \"자해\", \"위기\", \"긴급\", \"안전\"],\n",
    "    \"주거지원\": [\"거처\", \"임대\", \"전세\", \"월세\", \"보증금\", \"주거환경\"],\n",
    "    \"일자리\": [\"구직\", \"자활\", \"취업\", \"직업\", \"훈련\", \"능력개발\"],\n",
    "    \"아동지원\": [\"아동\", \"보육\", \"교육\", \"양육상담\", \"돌봄\"],\n",
    "    \"채무·법률\": [\"채무\", \"법률\", \"소송\", \"변호\", \"상담\", \"빚\"],\n",
    "    \"고립·고독\": [\"고독\", \"고립\", \"사회적\", \"외로움\", \"고독사\"]\n",
    "}\n",
    "\n",
    "# 카테고리 우선순위 정의\n",
    "priority_order = [\n",
    "    \"생계지원\", \"주거지원\", \"일자리\", \"아동지원\",\n",
    "    \"돌봄·보호\", \"건강·의료\", \"안전위기\", \"채무·법률\", \"고립·고독\"\n",
    "]\n",
    "\n",
    "# 카테고리 분류 함수 (항상 하나 선택)\n",
    "def assign_single_category(row):\n",
    "    text = \"\"\n",
    "    for col in [\"서비스 요약\", \"서비스내용\", \"신청방법상세\"]:\n",
    "        if col in df.columns and pd.notna(row[col]):\n",
    "            text += \" \" + str(row[col])\n",
    "    matched = [cat for cat, keywords in category_keywords.items() if any(k in text for k in keywords)]\n",
    "    for cat in priority_order:  # 우선순위대로 하나만 선택\n",
    "        if cat in matched:\n",
    "            return cat\n",
    "    return \"생계지원\"  # 매칭 없으면 기본값\n",
    "\n",
    "# 카테고리 갱신\n",
    "df[\"카테고리\"] = df.apply(assign_single_category, axis=1)\n",
    "\n",
    "# 저장\n",
    "output_path = \"local_final_welfare_list_categorized.csv\"\n",
    "df.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"✅ 카테고리 분류 완료, 저장된 파일:\", output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c9588e",
   "metadata": {},
   "source": [
    "## 중앙부처 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b678d1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# 파일 불러오기\n",
    "file_path = \"goverment_final_welfare_list_with_features.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 1. 상세링크 추가\n",
    "df[\"상세링크\"] = df[\"서비스ID\"].apply(\n",
    "    lambda x: f\"https://www.bokjiro.go.kr/ssis-tbu/twataa/wlfareInfo/moveTWAT52011M.do?wlfareInfoId={x}&wlfareInfoReldBztpCd=01\"\n",
    ")\n",
    "\n",
    "# 2. 대상특성 추출 함수\n",
    "def extract_target_feature(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    text = str(text)\n",
    "\n",
    "    # 나이 범위\n",
    "    match_range = re.search(r\"(\\d{1,2})\\s*~\\s*(\\d{1,2})세\", text)\n",
    "    if match_range:\n",
    "        return f\"{match_range.group(1)}~{match_range.group(2)}세\"\n",
    "    match_over = re.search(r\"만?\\s*(\\d{1,2})세\\s*이상\", text)\n",
    "    if match_over:\n",
    "        return f\"{match_over.group(1)}세 이상\"\n",
    "    match_under = re.search(r\"만?\\s*(\\d{1,2})세\\s*이하\", text)\n",
    "    if match_under:\n",
    "        return f\"{match_under.group(1)}세 이하\"\n",
    "\n",
    "    # 키워드 매핑\n",
    "    if re.search(r\"(청년|청소년)\", text):\n",
    "        return \"청년\"\n",
    "    if re.search(r\"(노인|노년|고령|어르신)\", text):\n",
    "        return \"노년\"\n",
    "    if re.search(r\"(저소득|차상위|기초생활|중위소득)\", text):\n",
    "        return \"저소득\"\n",
    "    if re.search(r\"(임신|출산|산모|임부)\", text):\n",
    "        return \"임산부\"\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "# 지원대상상세 기반 대상특성 생성\n",
    "if \"지원대상상세\" in df.columns:\n",
    "    df[\"대상특성\"] = df[\"지원대상상세\"].apply(extract_target_feature)\n",
    "else:\n",
    "    df[\"대상특성\"] = \"\"\n",
    "\n",
    "# 3. 카테고리 분류\n",
    "category_keywords = {\n",
    "    \"생계지원\": [\"식비\", \"주거비\", \"공과금\", \"생활비\", \"차상위\", \"긴급복지\", \"할인\"],\n",
    "    \"돌봄·보호\": [\"간병\", \"시설보호\", \"주야간\", \"보호자\", \"양육\", \"간호\"],\n",
    "    \"건강·의료\": [\"질병\", \"진단\", \"치료\", \"의료비\", \"병원\", \"임신\", \"출산\"],\n",
    "    \"일상생활\": [\"가사\", \"식사\", \"이동\", \"위생\", \"생활지원\"],\n",
    "    \"안전위기\": [\"폭력\", \"학대\", \"자해\", \"위기\", \"긴급\", \"안전\"],\n",
    "    \"주거지원\": [\"거처\", \"임대\", \"전세\", \"월세\", \"보증금\", \"주거환경\"],\n",
    "    \"일자리\": [\"구직\", \"자활\", \"취업\", \"직업\", \"훈련\", \"능력개발\"],\n",
    "    \"아동지원\": [\"아동\", \"보육\", \"교육\", \"양육상담\", \"돌봄\"],\n",
    "    \"채무·법률\": [\"채무\", \"법률\", \"소송\", \"변호\", \"상담\", \"빚\"],\n",
    "    \"고립·고독\": [\"고독\", \"고립\", \"사회적\", \"외로움\", \"고독사\"]\n",
    "}\n",
    "\n",
    "priority_order = [\n",
    "    \"생계지원\", \"주거지원\", \"일자리\", \"아동지원\",\n",
    "    \"돌봄·보호\", \"건강·의료\", \"안전위기\", \"채무·법률\", \"고립·고독\"\n",
    "]\n",
    "\n",
    "def assign_category(text):\n",
    "    if not text:\n",
    "        return \"생계지원\"  # 기본값\n",
    "    text = str(text)\n",
    "    matched = [cat for cat, keywords in category_keywords.items() if any(k in text for k in keywords)]\n",
    "    for cat in priority_order:\n",
    "        if cat in matched:\n",
    "            return cat\n",
    "    return \"생계지원\"\n",
    "\n",
    "# 서비스개요와 서비스명 기준으로 카테고리 분류\n",
    "if \"서비스개요\" in df.columns:\n",
    "    df[\"카테고리\"] = df[\"서비스개요\"].apply(assign_category)\n",
    "else:\n",
    "    df[\"카테고리\"] = df[\"서비스명\"].apply(assign_category)\n",
    "\n",
    "# 4. 저장\n",
    "output_path = \"goverment_final_welfare_list_categorized.csv\"\n",
    "df.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"✅ CSV 저장 완료:\", output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264b91df",
   "metadata": {},
   "source": [
    "민간복지 빈 칼럼 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af31642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 원본 파일 경로\n",
    "input_path = \"private_final_welfare_list.csv\"\n",
    "\n",
    "# 출력 파일 경로\n",
    "base, ext = os.path.splitext(input_path)\n",
    "output_path = base + \"_no_empty_cols\" + ext\n",
    "\n",
    "# 데이터 불러오기\n",
    "df = pd.read_csv(input_path, dtype=object)  # 모든 칼럼을 object로 읽으면 공백처리 안전\n",
    "\n",
    "def col_has_any_value(s: pd.Series) -> bool:\n",
    "    \"\"\"\n",
    "    시리즈가 '모두 빈 값'인지 검사.\n",
    "    - NaN은 빈값으로 처리\n",
    "    - 문자열일 경우 공백만 있는 것도 빈값으로 처리\n",
    "    - 숫자/기타 non-NaN 값은 값이 있는 것으로 간주\n",
    "    \"\"\"\n",
    "    # NaN을 빈 문자열로 대체(벡터화)\n",
    "    filled = s.where(s.notna(), \"\")\n",
    "    # 문자열로 변환 후 양쪽 공백 제거\n",
    "    stripped = filled.astype(str).str.strip()\n",
    "    # 하나라도 빈문자열이 아닌 값이 있으면 True\n",
    "    return (stripped != \"\").any()\n",
    "\n",
    "# 각 컬럼에 대해 비어있는지 검사\n",
    "has_value_mask = df.apply(col_has_any_value, axis=0)\n",
    "kept_columns = has_value_mask[has_value_mask].index.tolist()\n",
    "dropped_columns = has_value_mask[~has_value_mask].index.tolist()\n",
    "\n",
    "print(\"유지할 컬럼 개수:\", len(kept_columns))\n",
    "print(\"제거할 빈 컬럼들 (총 {}개):\".format(len(dropped_columns)))\n",
    "for c in dropped_columns:\n",
    "    print(\" -\", c)\n",
    "\n",
    "# 빈 컬럼 제거한 데이터프레임\n",
    "df_clean = df.loc[:, kept_columns]\n",
    "\n",
    "# 저장\n",
    "df_clean.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n",
    "print(\"저장 완료:\", output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcc47a0",
   "metadata": {},
   "source": [
    "민간복지 전처리-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec14302e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "input_path = \"private_final_welfare_list.csv\"\n",
    "output_path = \"private_final_welfare_list_standardized.csv\"\n",
    "\n",
    "# 안전하게 문자열로 읽기\n",
    "df = pd.read_csv(input_path, dtype=str)\n",
    "\n",
    "# (생략: 연령 추출 함수, 컬럼 rename 등 기존 코드 유지)\n",
    "# --- 여기에 앞서 사용하신 derive_age_from_text, 나이 생성 코드 등을 넣으시면 됩니다 ---\n",
    "# (예: derive_age_from_text 정의, '나이(코드기반)'/'나이' 생성 등)\n",
    "\n",
    "# ----------------------------\n",
    "# 빈 칼럼 검사 함수 (안전한 버전)\n",
    "# ----------------------------\n",
    "def col_has_any_value(s):\n",
    "    \"\"\"\n",
    "    시리즈나 1-컬럼 DataFrame을 받아서 '하나라도 값이 있는지' 검사.\n",
    "    - NaN/None -> 빈값\n",
    "    - 공백 문자열 -> 빈값\n",
    "    - 리스트/숫자/기타 객체도 str()로 변환 후 공백 판정\n",
    "    \"\"\"\n",
    "    # 만약 DataFrame이 들어오면 모든 원소를 순회하도록 flatten\n",
    "    if isinstance(s, pd.DataFrame):\n",
    "        iterator = s.itertuples(index=False, name=None)\n",
    "        for row in iterator:\n",
    "            # row는 튜플일 수 있음: 각 원소 검사\n",
    "            for val in row:\n",
    "                if val is None:\n",
    "                    continue\n",
    "                v = str(val).strip()\n",
    "                if v != \"\":\n",
    "                    return True\n",
    "        return False\n",
    "    # Series인 경우 (일반적)\n",
    "    for val in s:\n",
    "        if val is None or (isinstance(val, float) and pd.isna(val)):\n",
    "            continue\n",
    "        if str(val).strip() != \"\":\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# ----------------------------\n",
    "# 예: 기존 rename_map 적용 (사용자 코드 그대로 유지)\n",
    "# ----------------------------\n",
    "rename_map = {\n",
    "    \"서비스ID\": \"서비스ID\",\n",
    "    \"서비스명\": \"서비스명\",\n",
    "    \"서비스 요약\": \"서비스개요\",\n",
    "    \"서비스개요\": \"서비스개요\",\n",
    "    \"상세 링크\": \"상세링크\",\n",
    "    \"상세링크\": \"상세링크\",\n",
    "    \"소관기관\": \"소관부처\",\n",
    "    \"대표연락처\": \"대표연락처\",\n",
    "    \"시작일\": \"시작일\",\n",
    "    \"종료일\": \"종료일\",\n",
    "    \"진행상태\": \"사업상태\",\n",
    "    \"INTRS_THEMA_CD\": \"관심주제코드\",\n",
    "    \"FMLY_CIRC_CD\": \"대상특성코드\",\n",
    "    \"BKJR_LFTM_CYC_CD\": \"생애주기코드\",\n",
    "    \"WLFARE_INFO_AGGRP_CD\": \"나이\",\n",
    "    \"카테고리\": \"카테고리\",\n",
    "    \"사업목적\": \"서비스목적\",\n",
    "    \"지원대상\": \"지원대상상세\",\n",
    "    \"지원대상상세\": \"지원대상상세\",\n",
    "    \"지원내용\": \"서비스내용\",\n",
    "    \"서비스내용\": \"서비스내용\",\n",
    "    \"신청방법\": \"신청방법상세\",\n",
    "    \"신청방법상세\": \"신청방법상세\",\n",
    "    \"제출서류\": \"필요서류\",\n",
    "}\n",
    "\n",
    "existing_map = {k:v for k,v in rename_map.items() if k in df.columns}\n",
    "df = df.rename(columns=existing_map)\n",
    "\n",
    "# ----------------------------\n",
    "# 빈 칼럼 감지 및 삭제 (안전)\n",
    "# ----------------------------\n",
    "empty_cols = [c for c in df.columns if not col_has_any_value(df[c])]\n",
    "if empty_cols:\n",
    "    print(\"삭제할 빈 컬럼들:\", empty_cols)\n",
    "    df = df.drop(columns=empty_cols)\n",
    "else:\n",
    "    print(\"빈 컬럼 없음. 삭제할 항목 없음.\")\n",
    "\n",
    "# ----------------------------\n",
    "# 저장\n",
    "# ----------------------------\n",
    "df.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n",
    "print(\"저장 완료:\", os.path.abspath(output_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d3ed0e",
   "metadata": {},
   "source": [
    "민간복지 -최종"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa78162",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "# 입력 / 출력 파일 경로 (필요하면 경로를 수정)\n",
    "INPUT_PATH = \"private_final_welfare_list.csv\"\n",
    "OUTPUT_PATH = \"private_final_welfare_list_with_category.csv\"\n",
    "\n",
    "# 1) 카테고리 키워드 사전 (체크리스트 기준)\n",
    "category_keywords = {\n",
    "    \"생계지원\": [\"생계\", \"식비\", \"주거비\", \"공과금\", \"생활비\", \"긴급복지\", \"할인\", \"생활지원\", \"바우처\"],\n",
    "    \"돌봄·보호\": [\"간병\", \"시설보호\", \"주야간\", \"돌봄\", \"보호\", \"양육\", \"방문간호\", \"돌봄서비스\"],\n",
    "    \"건강·의료\": [\"질병\", \"진단\", \"치료\", \"의료\", \"병원\", \"건강검진\", \"의료비\", \"임신\", \"출산\", \"진료\"],\n",
    "    \"일상생활\": [\"가사\", \"식사\", \"이동\", \"위생\", \"일상생활\", \"생활지원\"],\n",
    "    \"안전위기\": [\"폭력\", \"학대\", \"자해\", \"위기\", \"긴급\", \"재난\", \"안전\", \"위험\"],\n",
    "    \"주거지원\": [\"거처\", \"주거\", \"전세\", \"월세\", \"보증금\", \"주거환경\", \"주택\", \"임대\", \"주택수리\"],\n",
    "    \"일자리\": [\"구직\", \"자활\", \"취업\", \"직업\", \"일자리\", \"직업능력\", \"훈련\", \"직업훈련\"],\n",
    "    \"아동지원\": [\"아동\", \"보육\", \"양육\", \"유아\", \"영유아\", \"초등\", \"청소년\"],\n",
    "    \"채무·법률\": [\"채무\", \"법률\", \"소송\", \"변호\", \"상담\", \"빚\", \"채권\", \"부채\"],\n",
    "    \"고립·고독\": [\"고립\", \"고독\", \"외로움\", \"사회적고립\", \"고독사\"]\n",
    "}\n",
    "\n",
    "# 2) 우선순위 (중복 매칭 시 이 순서로 먼저 선택)\n",
    "priority_order = [\n",
    "    \"생계지원\", \"주거지원\", \"일자리\", \"아동지원\",\n",
    "    \"돌봄·보호\", \"건강·의료\", \"안전위기\", \"채무·법률\", \"고립·고독\"\n",
    "]\n",
    "\n",
    "# 3) 파일 읽기\n",
    "if not os.path.exists(INPUT_PATH):\n",
    "    raise FileNotFoundError(f\"입력 파일이 없습니다: {INPUT_PATH}\")\n",
    "\n",
    "df = pd.read_csv(INPUT_PATH, dtype=str)\n",
    "\n",
    "# 4) 자동으로 검색할 텍스트 칼럼 후보 (존재하면 사용)\n",
    "text_candidates = [\n",
    "    \"서비스개요\", \"서비스 요약\", \"서비스내용\", \"지원내용\",\n",
    "    \"지원대상\", \"지원대상상세\", \"선정기준\", \"신청방법상세\", \"서비스명\"\n",
    "]\n",
    "text_cols = [c for c in text_candidates if c in df.columns]\n",
    "\n",
    "# 5) lower-case 키워드 준비\n",
    "category_keywords_lower = {k: [kw.lower() for kw in kws] for k,kws in category_keywords.items()}\n",
    "\n",
    "# 6) 행 텍스트 결합 함수\n",
    "def combined_text_for_row(row):\n",
    "    parts = []\n",
    "    for c in text_cols:\n",
    "        v = row.get(c, \"\")\n",
    "        if pd.notna(v) and str(v).strip() != \"\":\n",
    "            parts.append(str(v))\n",
    "    return \" \".join(parts).lower()  # 소문자로 변환하여 매칭 단순화\n",
    "\n",
    "# 7) 카테고리 할당 함수\n",
    "def assign_category(row):\n",
    "    text = combined_text_for_row(row)\n",
    "    matched = []\n",
    "    for cat, kws in category_keywords_lower.items():\n",
    "        for kw in kws:\n",
    "            if kw in text:\n",
    "                matched.append(cat)\n",
    "                break\n",
    "    # 우선순위에 따라 하나만 선택\n",
    "    for cat in priority_order:\n",
    "        if cat in matched:\n",
    "            return cat\n",
    "    # 아무것도 매칭되지 않으면 기본값 '생계지원'\n",
    "    return \"생계지원\"\n",
    "\n",
    "# 8) 카테고리 컬럼 생성 (덮어쓰기)\n",
    "df[\"카테고리\"] = df.apply(assign_category, axis=1)\n",
    "\n",
    "# 9) 결과 간단 통계 출력\n",
    "print(\"카테고리 분포:\")\n",
    "print(df[\"카테고리\"].value_counts(dropna=False))\n",
    "\n",
    "# 10) 저장\n",
    "df.to_csv(OUTPUT_PATH, index=False, encoding=\"utf-8-sig\")\n",
    "print(\"저장 완료:\", OUTPUT_PATH)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
